{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Reaction Prediction with Transformers (2025 Edition)\n",
    "\n",
    "![Molecular Transformer Animation](https://pubs.acs.org/cms/10.1021/acscentsci.9b00576/asset/images/medium/oc9b00576_0009.gif)\n",
    "<center><b>Figure 1:</b> SMILES-to-SMILES translation with the Molecular Transformer</center>\n",
    "\n",
    "---\n",
    "\n",
    "## Course: 06-731 Molecular Machine Learning\n",
    "**Original lecture by:** Philippe Schwaller (IBM Research / EPFL)  \n",
    "**Updated for 2025 by:** Gomes Group, Carnegie Mellon University\n",
    "\n",
    "---\n",
    "\n",
    "## What's New in This Version?\n",
    "\n",
    "This notebook is an updated version of the 2022 \"Digital Molecular Design Studio\" notebook on Chemical Language Models. Key changes include:\n",
    "\n",
    "| Component | 2022 Version | 2025 Version |\n",
    "|-----------|--------------|---------------|\n",
    "| **Framework** | OpenNMT-py 2.2.0 | HuggingFace Transformers (ReactionT5v2) |\n",
    "| **Model** | Custom Molecular Transformer | Pre-trained ReactionT5v2 |\n",
    "| **Python** | 3.6-3.8 | 3.10-3.12 |\n",
    "| **Training** | From scratch (24+ hours) | Fine-tuning (minutes) or inference-only |\n",
    "| **Atom Mapping** | Not included | RXNMapper integration |\n",
    "| **API Access** | Not available | rxn4chemistry (IBM RXN) |\n",
    "\n",
    "### Why the Change?\n",
    "\n",
    "1. **OpenNMT-py is deprecated** - The project announced it's \"no longer actively supported\" as of July 2024, with [Eole](https://github.com/eole-nlp/eole) as the successor.\n",
    "2. **pyonmttok dependency issues** - The tokenizer package fails on Python 3.12 (Google Colab's current version).\n",
    "3. **Better alternatives exist** - ReactionT5v2 offers state-of-the-art performance with easier setup.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Part 1: Setup and Foundations\n",
    "- [1.1 Environment Setup](#1.1)\n",
    "- [1.2 SMILES Representation Review](#1.2)\n",
    "- [1.3 Tokenization for Chemical Language Models](#1.3)\n",
    "\n",
    "### Part 2: Reaction Prediction with ReactionT5v2\n",
    "- [2.1 Loading Pre-trained Models](#2.1)\n",
    "- [2.2 Forward Reaction Prediction](#2.2)\n",
    "- [2.3 Batch Predictions and Evaluation](#2.3)\n",
    "- [2.4 Retrosynthesis Prediction](#2.4)\n",
    "\n",
    "### Part 3: Advanced Topics\n",
    "- [3.1 Atom Mapping with RXNMapper](#3.1)\n",
    "- [3.2 IBM RXN for Chemistry API](#3.2)\n",
    "- [3.3 Data Augmentation for SMILES](#3.3)\n",
    "- [3.4 Fine-tuning on Custom Datasets](#3.4)\n",
    "\n",
    "### Part 4: Visualization and Analysis\n",
    "- [4.1 Drawing Chemical Reactions](#4.1)\n",
    "- [4.2 Error Analysis and Debugging](#4.2)\n",
    "\n",
    "### Appendix\n",
    "- [A. Legacy OpenNMT-py Approach (Reference Only)](#appendix-a)\n",
    "- [B. Publications and Resources](#appendix-b)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Foundations\n",
    "\n",
    "<a id='1.1'></a>\n",
    "### 1.1 Environment Setup\n",
    "\n",
    "We'll install the necessary packages for this notebook. The installation is designed to work on Google Colab (Python 3.12) and local conda environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Environment Detection and Package Installation\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Core packages for chemical reaction prediction\n",
    "PACKAGES = [\n",
    "    \"rdkit\",                    # Cheminformatics toolkit\n",
    "    \"torch\",                    # PyTorch (usually pre-installed in Colab)\n",
    "    \"transformers>=4.40.0\",     # HuggingFace Transformers\n",
    "    \"tokenizers>=0.19.1\",       # Fast tokenizers\n",
    "    \"sentencepiece\",            # Tokenizer backend\n",
    "    \"accelerate\",               # Training acceleration\n",
    "    \"datasets\",                 # HuggingFace datasets\n",
    "    \"pandas\",                   # Data manipulation\n",
    "    \"gdown\",                    # Google Drive downloads\n",
    "    \"tqdm\",                     # Progress bars\n",
    "    \"plotly\",                   # Interactive visualization\n",
    "]\n",
    "\n",
    "def install_packages(packages):\n",
    "    \"\"\"Install packages with progress feedback.\"\"\"\n",
    "    for pkg in packages:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "    print(\"\\n[SUCCESS] All packages installed!\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    install_packages(PACKAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Configure Environment\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem, rdChemReactions\n",
    "from rdkit.Chem.Draw import rdMolDraw2D, IPythonConsole\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# HuggingFace imports\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Display settings\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "RDLogger.DisableLog('rdApp.*')  # Suppress RDKit warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Check GPU availability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(f\"\\nRDKit version: {Chem.rdBase.rdkitVersion}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Gomes Group Color Palette for Visualizations\n",
    "# Professional styling consistent with Gomes Group publications\n",
    "\n",
    "GOMES_COLORS = {\n",
    "    'teal': '#00D9FF',      # Primary accent\n",
    "    'coral': '#FF6B6B',     # Secondary accent / errors\n",
    "    'navy': '#0A1628',      # Dark background\n",
    "    'slate': '#2D3748',     # Text\n",
    "    'success': '#48BB78',   # Correct predictions\n",
    "    'warning': '#ECC94B',   # Warnings\n",
    "    'light_bg': '#F7FAFC',  # Light background\n",
    "}\n",
    "\n",
    "# Plotly template for consistent styling\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "GOMES_TEMPLATE = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        font=dict(family=\"Helvetica Neue, Arial, sans-serif\", size=14, color=GOMES_COLORS['slate']),\n",
    "        plot_bgcolor=GOMES_COLORS['light_bg'],\n",
    "        paper_bgcolor='white',\n",
    "        colorway=[GOMES_COLORS['teal'], GOMES_COLORS['coral'], GOMES_COLORS['success'], GOMES_COLORS['warning']],\n",
    "        title=dict(font=dict(size=20, color=GOMES_COLORS['navy'])),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Gomes Group styling configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 SMILES Representation Review\n",
    "\n",
    "**SMILES (Simplified Molecular Input Line Entry System)** is a line notation for representing molecules as text strings. For reaction prediction, we treat chemical reactions as a translation problem:\n",
    "\n",
    "```\n",
    "Reactants.Reagents >> Products\n",
    "```\n",
    "\n",
    "Key concepts:\n",
    "- **Atoms**: C, N, O, S, etc. (uppercase = aromatic, lowercase = aromatic ring member)\n",
    "- **Bonds**: Single (implicit or `-`), double (`=`), triple (`#`)\n",
    "- **Rings**: Numbers indicate ring closures (e.g., `C1CCCCC1` = cyclohexane)\n",
    "- **Branches**: Parentheses for branching (e.g., `CC(C)C` = isobutane)\n",
    "- **Stereochemistry**: `@`, `@@` for chirality; `/`, `\\` for cis/trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: SMILES Examples and Canonicalization\n",
    "\n",
    "def canonicalize_smiles(smiles: str, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to its canonical form.\n",
    "    \n",
    "    Canonicalization ensures that the same molecule always has the same SMILES,\n",
    "    regardless of how it was originally written. This is crucial for:\n",
    "    1. Comparing predictions to ground truth\n",
    "    2. Removing duplicates from datasets\n",
    "    3. Ensuring reproducibility\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input SMILES string\n",
    "        verbose: Print warning for invalid SMILES\n",
    "    \n",
    "    Returns:\n",
    "        Canonical SMILES or empty string if invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Warning: '{smiles}' could not be parsed as a valid molecule.\")\n",
    "            return ''\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing '{smiles}': {e}\")\n",
    "        return ''\n",
    "\n",
    "# Demonstrate canonicalization\n",
    "examples = [\n",
    "    (\"C(C)O\", \"Ethanol - different atom ordering\"),\n",
    "    (\"OCC\", \"Ethanol - starting from oxygen\"),\n",
    "    (\"CCO\", \"Ethanol - canonical form\"),\n",
    "    (\"c1ccccc1\", \"Benzene - aromatic notation\"),\n",
    "    (\"C1=CC=CC=C1\", \"Benzene - Kekule notation\"),\n",
    "]\n",
    "\n",
    "print(\"SMILES Canonicalization Examples:\")\n",
    "print(\"-\" * 60)\n",
    "for smiles, description in examples:\n",
    "    canonical = canonicalize_smiles(smiles)\n",
    "    print(f\"{smiles:20} -> {canonical:20} ({description})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualize molecules from SMILES\n",
    "\n",
    "def draw_molecules_grid(smiles_list: List[str], labels: Optional[List[str]] = None, \n",
    "                        mols_per_row: int = 4, img_size: Tuple[int, int] = (250, 200)):\n",
    "    \"\"\"\n",
    "    Draw a grid of molecules from SMILES strings.\n",
    "    \n",
    "    Args:\n",
    "        smiles_list: List of SMILES strings\n",
    "        labels: Optional labels for each molecule\n",
    "        mols_per_row: Number of molecules per row\n",
    "        img_size: Size of each molecule image\n",
    "    \n",
    "    Returns:\n",
    "        RDKit grid image\n",
    "    \"\"\"\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "    if labels is None:\n",
    "        labels = smiles_list\n",
    "    \n",
    "    return Draw.MolsToGridImage(\n",
    "        mols, \n",
    "        molsPerRow=mols_per_row, \n",
    "        subImgSize=img_size,\n",
    "        legends=labels\n",
    "    )\n",
    "\n",
    "# Example: Common functional groups in drug molecules\n",
    "drug_motifs = [\n",
    "    (\"c1ccccc1\", \"Benzene\"),\n",
    "    (\"c1ccncc1\", \"Pyridine\"),\n",
    "    (\"c1ccc2[nH]ccc2c1\", \"Indole\"),\n",
    "    (\"CC(=O)O\", \"Acetic acid\"),\n",
    "    (\"CC(=O)N\", \"Acetamide\"),\n",
    "    (\"c1ccc(O)cc1\", \"Phenol\"),\n",
    "    (\"c1ccc(N)cc1\", \"Aniline\"),\n",
    "    (\"CC(C)C\", \"Isobutane\"),\n",
    "]\n",
    "\n",
    "smiles_list, labels = zip(*drug_motifs)\n",
    "draw_molecules_grid(list(smiles_list), list(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Tokenization for Chemical Language Models\n",
    "\n",
    "Unlike natural language, SMILES requires **atom-wise tokenization** to preserve chemical meaning. We use a regex pattern that recognizes:\n",
    "\n",
    "- Multi-character elements (Br, Cl)\n",
    "- Bracketed atoms ([NH2], [Fe+2])\n",
    "- Ring numbers (including extended %XX notation)\n",
    "- Stereochemistry markers\n",
    "- Special symbols (reaction arrow `>>`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: SMILES Tokenization\n",
    "\n",
    "# Regex pattern from the original Molecular Transformer paper\n",
    "SMI_REGEX_PATTERN = r\"(\\%\\([0-9]{3}\\)|\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\||\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "\n",
    "def smiles_tokenizer(smiles: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES string into space-separated tokens.\n",
    "    \n",
    "    This tokenization preserves chemical meaning by keeping:\n",
    "    - Multi-character elements together (Br, Cl)\n",
    "    - Bracketed atoms as single tokens ([NH2])\n",
    "    - Ring numbers as single tokens\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input SMILES string\n",
    "    \n",
    "    Returns:\n",
    "        Space-separated tokenized SMILES\n",
    "    \"\"\"\n",
    "    regex = re.compile(SMI_REGEX_PATTERN)\n",
    "    tokens = regex.findall(smiles)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def detokenize_smiles(tokenized: str) -> str:\n",
    "    \"\"\"Convert tokenized SMILES back to standard SMILES.\"\"\"\n",
    "    return tokenized.replace(' ', '')\n",
    "\n",
    "# Demonstration\n",
    "test_smiles = [\n",
    "    \"CCO\",                                    # Simple: ethanol\n",
    "    \"CC(=O)Oc1ccccc1C(=O)O\",                  # Aspirin\n",
    "    \"[NH2]c1ccccc1Br\",                        # Bracketed atoms\n",
    "    \"CC.CC>>CCCC\",                            # Reaction SMILES\n",
    "    \"C[C@@H](O)CC\",                           # Stereochemistry\n",
    "]\n",
    "\n",
    "print(\"SMILES Tokenization Examples:\")\n",
    "print(\"=\" * 70)\n",
    "for smi in test_smiles:\n",
    "    tokenized = smiles_tokenizer(smi)\n",
    "    n_tokens = len(tokenized.split())\n",
    "    print(f\"\\nOriginal ({len(smi)} chars):\")\n",
    "    print(f\"  {smi}\")\n",
    "    print(f\"Tokenized ({n_tokens} tokens):\")\n",
    "    print(f\"  {tokenized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Reaction Prediction with ReactionT5v2\n",
    "\n",
    "<a id='2.1'></a>\n",
    "### 2.1 Loading Pre-trained Models\n",
    "\n",
    "**ReactionT5v2** is a T5 model pre-trained on the [Open Reaction Database (ORD)](https://github.com/open-reaction-database/ord-data), which contains millions of diverse chemical reactions. Unlike models trained on narrow patent datasets, ReactionT5 offers:\n",
    "\n",
    "- **Greater generalizability** across reaction types\n",
    "- **State-of-the-art performance** on standard benchmarks\n",
    "- **Easy fine-tuning** for specialized applications\n",
    "\n",
    "Available models on [HuggingFace](https://huggingface.co/collections/sagawa/reactiont5-67dbe0550cbb6886a85e348b):\n",
    "- `sagawa/ReactionT5v2-forward` - Forward reaction prediction (reactants -> products)\n",
    "- `sagawa/ReactionT5v2-retrosynthesis` - Retrosynthesis (products -> reactants)\n",
    "- `sagawa/ReactionT5v2-yield` - Yield prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load ReactionT5v2 Forward Model\n",
    "\n",
    "class ReactionT5Predictor:\n",
    "    \"\"\"\n",
    "    Wrapper class for ReactionT5v2 models providing easy-to-use prediction methods.\n",
    "    \n",
    "    This class handles:\n",
    "    - Model and tokenizer loading\n",
    "    - Input formatting (REACTANT:...REAGENT:... format)\n",
    "    - Batch prediction with beam search\n",
    "    - Output post-processing and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sagawa/ReactionT5v2-forward\", device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with a pre-trained model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model identifier\n",
    "            device: 'cuda' or 'cpu' (auto-detected if None)\n",
    "        \"\"\"\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        \n",
    "        # Load tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "    \n",
    "    def format_input(self, reactants: str, reagents: str = \" \") -> str:\n",
    "        \"\"\"\n",
    "        Format input for ReactionT5 models.\n",
    "        \n",
    "        Expected format: \"REACTANT:{smiles}REAGENT:{smiles}\"\n",
    "        If no reagents, use a space as placeholder.\n",
    "        \n",
    "        Args:\n",
    "            reactants: SMILES of reactants (concatenated with '.')\n",
    "            reagents: SMILES of reagents/catalysts/solvents (or ' ')\n",
    "        \n",
    "        Returns:\n",
    "            Formatted input string\n",
    "        \"\"\"\n",
    "        return f\"REACTANT:{reactants}REAGENT:{reagents}\"\n",
    "    \n",
    "    def predict(self, reactants: str, reagents: str = \" \", \n",
    "                num_beams: int = 5, num_return_sequences: int = 5,\n",
    "                max_length: int = 200) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict products for a single reaction.\n",
    "        \n",
    "        Args:\n",
    "            reactants: SMILES of reactants\n",
    "            reagents: SMILES of reagents (default: ' ' for none)\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Number of predictions to return\n",
    "            max_length: Maximum output sequence length\n",
    "        \n",
    "        Returns:\n",
    "            List of dicts with 'smiles', 'canonical', 'valid', 'score' keys\n",
    "        \"\"\"\n",
    "        # Format and tokenize input\n",
    "        input_text = self.format_input(reactants, reagents)\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                max_length=max_length,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "            )\n",
    "        \n",
    "        # Decode and validate predictions\n",
    "        results = []\n",
    "        for seq in outputs.sequences:\n",
    "            pred_smiles = self.tokenizer.decode(seq, skip_special_tokens=True)\n",
    "            pred_smiles = pred_smiles.replace(' ', '').rstrip('.')\n",
    "            canonical = canonicalize_smiles(pred_smiles)\n",
    "            \n",
    "            results.append({\n",
    "                'smiles': pred_smiles,\n",
    "                'canonical': canonical,\n",
    "                'valid': canonical != '',\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, reactions: List[Dict], batch_size: int = 16,\n",
    "                      num_beams: int = 5, num_return_sequences: int = 5) -> List[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Batch prediction for multiple reactions.\n",
    "        \n",
    "        Args:\n",
    "            reactions: List of dicts with 'reactants' and optionally 'reagents' keys\n",
    "            batch_size: Batch size for inference\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Predictions per reaction\n",
    "        \n",
    "        Returns:\n",
    "            List of prediction lists (one per input reaction)\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(reactions), batch_size), desc=\"Predicting\"):\n",
    "            batch = reactions[i:i+batch_size]\n",
    "            \n",
    "            # Format inputs\n",
    "            input_texts = [\n",
    "                self.format_input(r['reactants'], r.get('reagents', ' '))\n",
    "                for r in batch\n",
    "            ]\n",
    "            \n",
    "            inputs = self.tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    num_beams=num_beams,\n",
    "                    num_return_sequences=num_return_sequences,\n",
    "                    max_length=200,\n",
    "                )\n",
    "            \n",
    "            # Decode outputs\n",
    "            decoded = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            \n",
    "            # Group by input reaction\n",
    "            for j in range(len(batch)):\n",
    "                start_idx = j * num_return_sequences\n",
    "                end_idx = start_idx + num_return_sequences\n",
    "                \n",
    "                preds = []\n",
    "                for pred in decoded[start_idx:end_idx]:\n",
    "                    pred = pred.replace(' ', '').rstrip('.')\n",
    "                    canonical = canonicalize_smiles(pred)\n",
    "                    preds.append({\n",
    "                        'smiles': pred,\n",
    "                        'canonical': canonical,\n",
    "                        'valid': canonical != '',\n",
    "                    })\n",
    "                all_results.append(preds)\n",
    "        \n",
    "        return all_results\n",
    "\n",
    "# Initialize the predictor\n",
    "print(\"Initializing ReactionT5v2 Forward Predictor...\")\n",
    "print(\"(This may take a moment to download the model)\")\n",
    "print()\n",
    "\n",
    "forward_predictor = ReactionT5Predictor(\"sagawa/ReactionT5v2-forward\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### 2.2 Forward Reaction Prediction\n",
    "\n",
    "Let's test the model on some example reactions. We'll predict products from reactants and reagents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Single Reaction Prediction Examples\n",
    "\n",
    "# Example reactions with known products\n",
    "test_reactions = [\n",
    "    {\n",
    "        \"name\": \"Esterification (Fischer)\",\n",
    "        \"reactants\": \"CC(=O)O.CCO\",  # Acetic acid + Ethanol\n",
    "        \"reagents\": \" \",  # Acid catalyst (implicit)\n",
    "        \"expected\": \"CCOC(C)=O\",  # Ethyl acetate\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Suzuki Coupling\",\n",
    "        \"reactants\": \"Brc1ccccc1.OB(O)c1ccccc1\",  # Bromobenzene + Phenylboronic acid\n",
    "        \"reagents\": \"[Pd]\",  # Palladium catalyst\n",
    "        \"expected\": \"c1ccc(-c2ccccc2)cc1\",  # Biphenyl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Amide Formation\",\n",
    "        \"reactants\": \"CC(=O)O.NCC\",  # Acetic acid + Ethylamine\n",
    "        \"reagents\": \" \",\n",
    "        \"expected\": \"CCNC(C)=O\",  # N-ethylacetamide\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Grignard Addition\",\n",
    "        \"reactants\": \"CC=O.[Mg]Br\",  # Acetaldehyde + MgBr\n",
    "        \"reagents\": \"CCCC\",  # Butyl (as Grignard)\n",
    "        \"expected\": \"CCCCC(C)O\",  # 2-hexanol\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Forward Reaction Prediction Examples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for rxn in test_reactions:\n",
    "    print(f\"\\n{rxn['name']}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Reactants: {rxn['reactants']}\")\n",
    "    print(f\"Reagents:  {rxn['reagents']}\")\n",
    "    print(f\"Expected:  {rxn['expected']}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = forward_predictor.predict(\n",
    "        rxn['reactants'], \n",
    "        rxn['reagents'],\n",
    "        num_beams=5,\n",
    "        num_return_sequences=3\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPredictions:\")\n",
    "    expected_canonical = canonicalize_smiles(rxn['expected'])\n",
    "    \n",
    "    for i, pred in enumerate(predictions, 1):\n",
    "        status = \"[CORRECT]\" if pred['canonical'] == expected_canonical else \"\"\n",
    "        valid = \"valid\" if pred['valid'] else \"INVALID\"\n",
    "        print(f\"  {i}. {pred['canonical']:40} ({valid}) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualize a Predicted Reaction\n",
    "from IPython.display import SVG, display, HTML\n",
    "\n",
    "def draw_chemical_reaction(rxn_smiles: str, highlight_by_reactant: bool = True,\n",
    "                           use_smiles: bool = True, width: int = 800, height: int = 250) -> str:\n",
    "    \"\"\"\n",
    "    Draw a chemical reaction from SMILES.\n",
    "    \n",
    "    Args:\n",
    "        rxn_smiles: Reaction SMILES (format: reactants>>products)\n",
    "        highlight_by_reactant: Color atoms by which reactant they came from\n",
    "        use_smiles: Parse as SMILES (True) or SMARTS (False)\n",
    "        width: Image width\n",
    "        height: Image height\n",
    "    \n",
    "    Returns:\n",
    "        SVG string of the reaction drawing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rxn = rdChemReactions.ReactionFromSmarts(rxn_smiles, useSmiles=use_smiles)\n",
    "        d2d = rdMolDraw2D.MolDraw2DSVG(width, height)\n",
    "        d2d.drawOptions().annotationFontScale = 1.2\n",
    "        d2d.DrawReaction(rxn, highlightByReactant=highlight_by_reactant)\n",
    "        d2d.FinishDrawing()\n",
    "        return d2d.GetDrawingText()\n",
    "    except Exception as e:\n",
    "        return f\"<p>Error drawing reaction: {e}</p>\"\n",
    "\n",
    "# Draw the first test reaction with its prediction\n",
    "rxn = test_reactions[0]\n",
    "predictions = forward_predictor.predict(rxn['reactants'], rxn['reagents'], num_return_sequences=1)\n",
    "pred_smiles = predictions[0]['canonical']\n",
    "\n",
    "print(f\"Reaction: {rxn['name']}\")\n",
    "print(f\"Input: {rxn['reactants']}\")\n",
    "print(f\"Predicted Product: {pred_smiles}\")\n",
    "print(f\"Expected Product: {rxn['expected']}\")\n",
    "\n",
    "rxn_smiles = f\"{rxn['reactants']}>>{pred_smiles}\"\n",
    "display(SVG(draw_chemical_reaction(rxn_smiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### 2.3 Batch Predictions and Evaluation\n",
    "\n",
    "Now let's evaluate the model on a larger dataset. We'll download a subset of the USPTO dataset and compute standard metrics (Top-1, Top-3, Top-5 accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Download USPTO Dataset Subset\n",
    "import gdown\n",
    "\n",
    "def download_uspto_data(data_dir: str = \"USPTO_480k\") -> None:\n",
    "    \"\"\"\n",
    "    Download USPTO 480k reaction dataset.\n",
    "    \n",
    "    This dataset contains ~480,000 reactions from US patents,\n",
    "    split into train/val/test sets.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Google Drive links for USPTO_480k\n",
    "    files = [\n",
    "        (\"https://drive.google.com/uc?id=1RysNBvB2rsMP0Ap9XXi02XiiZkEXCrA8\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1CxxcVqtmOmHE2nhmqPFA6bilavzpcIlb\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FFN1nz2yB4VwrpWaBuiBDzFzdX3ONBsy\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1pYCjWkYvgp1ZQ78EKQBArOvt_2P1KnmI\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=10t6pHj9yR8Tp3kDvG0KMHl7Bt_TUbQ8W\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FeGuiGuz0chVBRgePMu0pGJA4FVReA-b\", \"tgt-test.txt\"),\n",
    "    ]\n",
    "    \n",
    "    for url, filename in files:\n",
    "        target = os.path.join(data_dir, filename)\n",
    "        if not os.path.exists(target):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            gdown.download(url, target, quiet=False)\n",
    "        else:\n",
    "            print(f\"{filename} already exists.\")\n",
    "\n",
    "def load_uspto_data(data_dir: str = \"USPTO_480k\", split: str = \"val\", \n",
    "                    max_samples: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load USPTO dataset into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files\n",
    "        split: 'train', 'val', or 'test'\n",
    "        max_samples: Maximum number of samples to load (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with 'precursors' and 'products' columns\n",
    "    \"\"\"\n",
    "    src_file = os.path.join(data_dir, f\"src-{split}.txt\")\n",
    "    tgt_file = os.path.join(data_dir, f\"tgt-{split}.txt\")\n",
    "    \n",
    "    with open(src_file, 'r') as f:\n",
    "        precursors = [line.strip().replace(' ', '') for line in f]\n",
    "    with open(tgt_file, 'r') as f:\n",
    "        products = [line.strip().replace(' ', '') for line in f]\n",
    "    \n",
    "    df = pd.DataFrame({'precursors': precursors, 'products': products})\n",
    "    \n",
    "    if max_samples:\n",
    "        df = df.head(max_samples)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Download and load data\n",
    "print(\"Downloading USPTO 480k dataset...\")\n",
    "download_uspto_data()\n",
    "\n",
    "# For demonstration, we'll use a smaller subset\n",
    "N_EVAL_SAMPLES = 100  # Use 100 samples for quick evaluation\n",
    "val_df = load_uspto_data(split=\"val\", max_samples=N_EVAL_SAMPLES)\n",
    "\n",
    "print(f\"\\nLoaded {len(val_df)} validation reactions\")\n",
    "print(\"\\nSample reactions:\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Evaluate Model on USPTO Validation Set\n",
    "\n",
    "def evaluate_predictions(df: pd.DataFrame, predictor: ReactionT5Predictor,\n",
    "                        n_best: int = 5, batch_size: int = 16) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate model predictions against ground truth.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'precursors' and 'products' columns\n",
    "        predictor: ReactionT5Predictor instance\n",
    "        n_best: Number of predictions per reaction\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions and evaluation metrics\n",
    "    \"\"\"\n",
    "    # Prepare reactions for batch prediction\n",
    "    reactions = [{'reactants': row['precursors'], 'reagents': ' '} \n",
    "                 for _, row in df.iterrows()]\n",
    "    \n",
    "    # Get predictions\n",
    "    all_predictions = predictor.predict_batch(\n",
    "        reactions, \n",
    "        batch_size=batch_size,\n",
    "        num_beams=n_best,\n",
    "        num_return_sequences=n_best\n",
    "    )\n",
    "    \n",
    "    # Add predictions to DataFrame\n",
    "    results = df.copy()\n",
    "    results['target_canonical'] = results['products'].apply(canonicalize_smiles)\n",
    "    \n",
    "    # Store predictions\n",
    "    for i in range(n_best):\n",
    "        results[f'pred_{i+1}'] = [preds[i]['canonical'] if i < len(preds) else '' \n",
    "                                   for preds in all_predictions]\n",
    "        results[f'pred_{i+1}_valid'] = [preds[i]['valid'] if i < len(preds) else False \n",
    "                                         for preds in all_predictions]\n",
    "    \n",
    "    # Calculate rank of correct prediction\n",
    "    def get_rank(row):\n",
    "        target = row['target_canonical']\n",
    "        for i in range(1, n_best + 1):\n",
    "            if row[f'pred_{i}'] == target:\n",
    "                return i\n",
    "        return 0  # Not found\n",
    "    \n",
    "    results['rank'] = results.apply(get_rank, axis=1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation (this may take a few minutes)\n",
    "print(f\"Evaluating on {len(val_df)} reactions...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "eval_results = evaluate_predictions(val_df, forward_predictor, n_best=5, batch_size=8)\n",
    "\n",
    "# Calculate metrics\n",
    "n_total = len(eval_results)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for k in [1, 2, 3, 5]:\n",
    "    correct = (eval_results['rank'] > 0) & (eval_results['rank'] <= k)\n",
    "    accuracy = correct.sum() / n_total * 100\n",
    "    print(f\"Top-{k} Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "# Invalid SMILES rate\n",
    "invalid_rate = (~eval_results['pred_1_valid']).sum() / n_total * 100\n",
    "print(f\"\\nInvalid Top-1 SMILES: {invalid_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Visualize Evaluation Results\n",
    "\n",
    "# Create accuracy bar chart\n",
    "accuracies = []\n",
    "for k in [1, 2, 3, 4, 5]:\n",
    "    correct = (eval_results['rank'] > 0) & (eval_results['rank'] <= k)\n",
    "    accuracy = correct.sum() / len(eval_results) * 100\n",
    "    accuracies.append({'k': f'Top-{k}', 'accuracy': accuracy})\n",
    "\n",
    "acc_df = pd.DataFrame(accuracies)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=acc_df['k'],\n",
    "    y=acc_df['accuracy'],\n",
    "    marker_color=GOMES_COLORS['teal'],\n",
    "    text=[f\"{a:.1f}%\" for a in acc_df['accuracy']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=GOMES_TEMPLATE,\n",
    "    title='ReactionT5v2 Accuracy on USPTO Validation Set',\n",
    "    xaxis_title='',\n",
    "    yaxis_title='Accuracy (%)',\n",
    "    yaxis_range=[0, 100],\n",
    "    showlegend=False,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "### 2.4 Retrosynthesis Prediction\n",
    "\n",
    "Retrosynthesis is the reverse problem: given a target product, predict the reactants needed to synthesize it. This is crucial for drug discovery and chemical manufacturing.\n",
    "\n",
    "ReactionT5v2 also provides a retrosynthesis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Retrosynthesis Predictor\n",
    "\n",
    "class RetrosynthesisPredictor:\n",
    "    \"\"\"\n",
    "    Wrapper for ReactionT5v2 retrosynthesis model.\n",
    "    \n",
    "    Given a target product, predicts possible reactants.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sagawa/ReactionT5v2-retrosynthesis\", device: str = None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        print(f\"Loading retrosynthesis model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(\"Model loaded!\")\n",
    "    \n",
    "    def predict(self, product: str, num_beams: int = 10, \n",
    "                num_return_sequences: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict reactants for a target product.\n",
    "        \n",
    "        Args:\n",
    "            product: SMILES of target product\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Number of predictions\n",
    "        \n",
    "        Returns:\n",
    "            List of predicted reactant sets\n",
    "        \"\"\"\n",
    "        input_text = f\"PRODUCT:{product}\"\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                max_length=200,\n",
    "            )\n",
    "        \n",
    "        results = []\n",
    "        for seq in outputs:\n",
    "            pred = self.tokenizer.decode(seq, skip_special_tokens=True)\n",
    "            pred = pred.replace(' ', '').rstrip('.')\n",
    "            \n",
    "            # Validate each reactant\n",
    "            reactants = pred.split('.')\n",
    "            valid = all(canonicalize_smiles(r) != '' for r in reactants if r)\n",
    "            \n",
    "            results.append({\n",
    "                'reactants': pred,\n",
    "                'valid': valid,\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Load retrosynthesis model\n",
    "print(\"Loading retrosynthesis model...\")\n",
    "retro_predictor = RetrosynthesisPredictor(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Retrosynthesis Examples\n",
    "\n",
    "# Target molecules for retrosynthesis\n",
    "targets = [\n",
    "    {\n",
    "        \"name\": \"Aspirin\",\n",
    "        \"smiles\": \"CC(=O)Oc1ccccc1C(=O)O\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ibuprofen\",\n",
    "        \"smiles\": \"CC(C)Cc1ccc(C(C)C(=O)O)cc1\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ethyl Acetate\",\n",
    "        \"smiles\": \"CCOC(C)=O\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Retrosynthesis Predictions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\nTarget: {target['name']}\")\n",
    "    print(f\"SMILES: {target['smiles']}\")\n",
    "    \n",
    "    # Show target molecule\n",
    "    mol = Chem.MolFromSmiles(target['smiles'])\n",
    "    display(mol)\n",
    "    \n",
    "    # Get retrosynthesis predictions\n",
    "    predictions = retro_predictor.predict(target['smiles'], num_return_sequences=3)\n",
    "    \n",
    "    print(\"\\nPredicted Reactants:\")\n",
    "    for i, pred in enumerate(predictions, 1):\n",
    "        valid_str = \"valid\" if pred['valid'] else \"INVALID\"\n",
    "        print(f\"  {i}. {pred['reactants']} ({valid_str})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Advanced Topics\n",
    "\n",
    "<a id='3.1'></a>\n",
    "### 3.1 Atom Mapping with RXNMapper\n",
    "\n",
    "Atom mapping shows which atoms in the reactants correspond to which atoms in the products. This is crucial for understanding reaction mechanisms.\n",
    "\n",
    "[RXNMapper](https://github.com/rxn4chemistry/rxnmapper) uses transformer attention to learn atom correspondences without supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Install and Setup RXNMapper\n",
    "\n",
    "# RXNMapper installation (may require specific handling for Colab)\n",
    "try:\n",
    "    from rxnmapper import RXNMapper\n",
    "    RXNMAPPER_AVAILABLE = True\n",
    "    print(\"RXNMapper is available!\")\n",
    "except ImportError:\n",
    "    print(\"Installing RXNMapper...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rxnmapper\"])\n",
    "    \n",
    "    try:\n",
    "        from rxnmapper import RXNMapper\n",
    "        RXNMAPPER_AVAILABLE = True\n",
    "        print(\"RXNMapper installed successfully!\")\n",
    "    except ImportError as e:\n",
    "        RXNMAPPER_AVAILABLE = False\n",
    "        print(f\"RXNMapper installation failed: {e}\")\n",
    "        print(\"This is optional - the notebook will continue without atom mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Atom Mapping Examples\n",
    "\n",
    "if RXNMAPPER_AVAILABLE:\n",
    "    # Initialize RXNMapper\n",
    "    rxn_mapper = RXNMapper()\n",
    "    \n",
    "    # Example reactions for atom mapping\n",
    "    reactions_to_map = [\n",
    "        \"CC(=O)O.CCO>>CCOC(C)=O.O\",  # Esterification\n",
    "        \"Brc1ccccc1.OB(O)c1ccccc1>>c1ccc(-c2ccccc2)cc1\",  # Suzuki coupling\n",
    "        \"c1ccccc1.Cl>>Clc1ccccc1\",  # Chlorination\n",
    "    ]\n",
    "    \n",
    "    print(\"Atom Mapping Examples\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for rxn in reactions_to_map:\n",
    "        print(f\"\\nReaction: {rxn}\")\n",
    "        \n",
    "        # Get atom mapping\n",
    "        result = rxn_mapper.get_attention_guided_atom_maps([rxn])[0]\n",
    "        mapped_rxn = result['mapped_rxn']\n",
    "        confidence = result['confidence']\n",
    "        \n",
    "        print(f\"Mapped:   {mapped_rxn}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "        \n",
    "        # Draw the mapped reaction\n",
    "        try:\n",
    "            display(SVG(draw_chemical_reaction(mapped_rxn, use_smiles=True)))\n",
    "        except:\n",
    "            print(\"(Could not render reaction image)\")\n",
    "else:\n",
    "    print(\"RXNMapper not available. Skipping atom mapping examples.\")\n",
    "    print(\"You can still use the model for reaction prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "### 3.2 IBM RXN for Chemistry API\n",
    "\n",
    "[IBM RXN for Chemistry](https://rxn.res.ibm.com) provides access to production-grade reaction prediction models through a REST API. This is useful for:\n",
    "\n",
    "- Access to models trained on larger datasets\n",
    "- Production applications\n",
    "- No local GPU required\n",
    "\n",
    "**Note:** You need a free API key from [rxn.res.ibm.com](https://rxn.res.ibm.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: IBM RXN for Chemistry Setup (Optional)\n",
    "\n",
    "# Install rxn4chemistry client\n",
    "try:\n",
    "    from rxn4chemistry import RXN4ChemistryWrapper\n",
    "    RXN4CHEM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rxn4chemistry\"])\n",
    "    try:\n",
    "        from rxn4chemistry import RXN4ChemistryWrapper\n",
    "        RXN4CHEM_AVAILABLE = True\n",
    "    except:\n",
    "        RXN4CHEM_AVAILABLE = False\n",
    "\n",
    "if RXN4CHEM_AVAILABLE:\n",
    "    print(\"rxn4chemistry is available!\")\n",
    "    print(\"\")\n",
    "    print(\"To use IBM RXN for Chemistry:\")\n",
    "    print(\"1. Create a free account at https://rxn.res.ibm.com\")\n",
    "    print(\"2. Get your API key from your profile settings\")\n",
    "    print(\"3. Set it below:\")\n",
    "    print(\"\")\n",
    "    print(\"# Example usage:\")\n",
    "    print(\"# api_key = 'YOUR_API_KEY_HERE'\")\n",
    "    print(\"# rxn = RXN4ChemistryWrapper(api_key=api_key)\")\n",
    "    print(\"# rxn.create_project('my_project')\")\n",
    "    print(\"# rxn.predict_reaction('BrBr.c1ccc2cc3ccccc3cc2c1')\")\n",
    "else:\n",
    "    print(\"rxn4chemistry not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: IBM RXN API Example (requires API key)\n",
    "\n",
    "# Uncomment and fill in your API key to use\n",
    "USE_IBM_RXN = False  # Set to True if you have an API key\n",
    "\n",
    "if USE_IBM_RXN and RXN4CHEM_AVAILABLE:\n",
    "    # Replace with your actual API key\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  \n",
    "    \n",
    "    rxn = RXN4ChemistryWrapper(api_key=api_key)\n",
    "    rxn.create_project('reaction_prediction_demo')\n",
    "    \n",
    "    # Predict a reaction\n",
    "    reactants = \"CC(=O)O.CCO\"  # Acetic acid + Ethanol\n",
    "    result = rxn.predict_reaction(reactants)\n",
    "    \n",
    "    print(f\"Input: {reactants}\")\n",
    "    print(f\"Predicted products: {result}\")\n",
    "else:\n",
    "    print(\"IBM RXN API demo skipped.\")\n",
    "    print(\"Set USE_IBM_RXN = True and provide your API key to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "### 3.3 Data Augmentation for SMILES\n",
    "\n",
    "A key technique for improving chemical language models is **SMILES randomization**. Since the same molecule can be written as many different valid SMILES strings, we can augment training data by generating alternative representations.\n",
    "\n",
    "This teaches the model that different SMILES can represent the same molecule, improving generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: SMILES Randomization Functions\n",
    "\n",
    "def randomize_smiles(smiles: str, random_type: str = \"rotated\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generate a random but equivalent SMILES representation.\n",
    "    \n",
    "    Three randomization strategies:\n",
    "    - 'rotated': Change the starting atom (preserves ring-opening order)\n",
    "    - 'restricted': Shuffle atom order with some constraints\n",
    "    - 'unrestricted': Full random atom ordering\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input canonical SMILES\n",
    "        random_type: Randomization strategy\n",
    "    \n",
    "    Returns:\n",
    "        Randomized SMILES or None if invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None\n",
    "    \n",
    "    if random_type == \"unrestricted\":\n",
    "        # Full random SMILES (most diverse)\n",
    "        return Chem.MolToSmiles(mol, canonical=False, doRandom=True, isomericSmiles=True)\n",
    "    \n",
    "    elif random_type == \"restricted\":\n",
    "        # Random atom order with some constraints\n",
    "        new_atom_order = list(range(mol.GetNumAtoms()))\n",
    "        random.shuffle(new_atom_order)\n",
    "        random_mol = Chem.RenumberAtoms(mol, newOrder=new_atom_order)\n",
    "        return Chem.MolToSmiles(random_mol, canonical=False, isomericSmiles=True)\n",
    "    \n",
    "    elif random_type == \"rotated\":\n",
    "        # Rotate starting atom (least disruptive)\n",
    "        n_atoms = mol.GetNumAtoms()\n",
    "        rotation_index = random.randint(0, n_atoms - 1)\n",
    "        atoms = list(range(n_atoms))\n",
    "        new_order = atoms[rotation_index:] + atoms[:rotation_index]\n",
    "        rotated_mol = Chem.RenumberAtoms(mol, new_order)\n",
    "        return Chem.MolToSmiles(rotated_mol, canonical=False, isomericSmiles=True)\n",
    "    \n",
    "    raise ValueError(f\"Unknown random_type: {random_type}\")\n",
    "\n",
    "# Demonstrate SMILES randomization\n",
    "caffeine = \"Cn1cnc2c1c(=O)n(c(=O)n2C)C\"  # Caffeine\n",
    "canonical = canonicalize_smiles(caffeine)\n",
    "\n",
    "print(f\"Canonical SMILES: {canonical}\")\n",
    "print(\"\\nRandomized versions:\")\n",
    "\n",
    "for rand_type in [\"rotated\", \"restricted\", \"unrestricted\"]:\n",
    "    print(f\"\\n{rand_type.upper()}:\")\n",
    "    unique_smiles = set()\n",
    "    for _ in range(100):\n",
    "        rand_smi = randomize_smiles(canonical, rand_type)\n",
    "        if rand_smi:\n",
    "            unique_smiles.add(rand_smi)\n",
    "    \n",
    "    print(f\"  Generated {len(unique_smiles)} unique SMILES from 100 attempts\")\n",
    "    print(f\"  Examples: {list(unique_smiles)[:3]}\")\n",
    "\n",
    "# Verify all random SMILES canonicalize to the same molecule\n",
    "print(\"\\nValidation: All random SMILES should canonicalize to the same molecule\")\n",
    "test_smiles = [randomize_smiles(canonical, \"unrestricted\") for _ in range(10)]\n",
    "canonicalized = set(canonicalize_smiles(s) for s in test_smiles if s)\n",
    "print(f\"Unique canonical forms: {canonicalized}\")\n",
    "assert len(canonicalized) == 1, \"Error: Different molecules produced!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Data Augmentation for Reaction Datasets\n",
    "\n",
    "def augment_reaction_dataset(df: pd.DataFrame, n_augmentations: int = 1,\n",
    "                              random_type: str = \"rotated\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Augment a reaction dataset with randomized SMILES.\n",
    "    \n",
    "    Each reaction is copied with randomized precursor SMILES.\n",
    "    Products are kept canonical (as targets should be deterministic).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'precursors' and 'products' columns\n",
    "        n_augmentations: Number of augmented copies per reaction\n",
    "        random_type: SMILES randomization strategy\n",
    "    \n",
    "    Returns:\n",
    "        Augmented DataFrame\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting\"):\n",
    "        # Original reaction\n",
    "        augmented_data.append({\n",
    "            'precursors': row['precursors'],\n",
    "            'products': row['products'],\n",
    "            'is_augmented': False\n",
    "        })\n",
    "        \n",
    "        # Augmented copies\n",
    "        for _ in range(n_augmentations):\n",
    "            # Randomize each reactant separately\n",
    "            reactants = row['precursors'].split('.')\n",
    "            rand_reactants = []\n",
    "            for r in reactants:\n",
    "                rand_r = randomize_smiles(r, random_type)\n",
    "                rand_reactants.append(rand_r if rand_r else r)\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'precursors': '.'.join(rand_reactants),\n",
    "                'products': row['products'],\n",
    "                'is_augmented': True\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "# Demonstrate augmentation on a small subset\n",
    "sample_df = val_df.head(5)\n",
    "augmented_df = augment_reaction_dataset(sample_df, n_augmentations=2)\n",
    "\n",
    "print(f\"Original dataset: {len(sample_df)} reactions\")\n",
    "print(f\"Augmented dataset: {len(augmented_df)} reactions\")\n",
    "print(f\"Augmentation factor: {len(augmented_df) / len(sample_df):.1f}x\")\n",
    "print(\"\\nSample augmented data:\")\n",
    "augmented_df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "### 3.4 Fine-tuning on Custom Datasets\n",
    "\n",
    "If you have a specialized reaction type (e.g., enzymatic reactions, photochemistry), you can fine-tune ReactionT5 on your own data. The model shows strong performance even with small datasets (~100-200 reactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Fine-tuning Setup (Conceptual)\n",
    "\n",
    "# This cell shows the structure for fine-tuning.\n",
    "# For actual fine-tuning, you would need to prepare your dataset and run training.\n",
    "\n",
    "print(\"\"\"\n",
    "Fine-tuning ReactionT5v2 on Custom Data\n",
    "========================================\n",
    "\n",
    "Step 1: Prepare your data as a CSV file with columns:\n",
    "  - REACTANT: SMILES of reactants (multiple compounds joined with '.')\n",
    "  - REAGENT: SMILES of reagents/catalysts (or ' ' if none)\n",
    "  - PRODUCT: SMILES of products\n",
    "\n",
    "Step 2: Clone the ReactionT5v2 repository:\n",
    "  git clone https://github.com/sagawatatsuya/ReactionT5v2\n",
    "  cd ReactionT5v2\n",
    "\n",
    "Step 3: Run fine-tuning:\n",
    "  cd task_forward\n",
    "  python finetune.py \\\\\n",
    "      --model_name_or_path='sagawa/ReactionT5v2-forward' \\\\\n",
    "      --epochs=50 \\\\\n",
    "      --batch_size=32 \\\\\n",
    "      --train_data_path='your_train.csv' \\\\\n",
    "      --valid_data_path='your_valid.csv' \\\\\n",
    "      --output_dir='output'\n",
    "\n",
    "Tips for fine-tuning:\n",
    "  - Start with a small learning rate (1e-4 to 1e-5)\n",
    "  - Use early stopping based on validation loss\n",
    "  - Augment small datasets with SMILES randomization\n",
    "  - Consider transfer learning from related reaction types\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Visualization and Analysis\n",
    "\n",
    "<a id='4.1'></a>\n",
    "### 4.1 Drawing Chemical Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Enhanced Reaction Drawing\n",
    "\n",
    "def draw_reaction_comparison(precursors: str, predicted: str, expected: str,\n",
    "                             title: str = \"Reaction Comparison\") -> None:\n",
    "    \"\"\"\n",
    "    Draw predicted vs expected reaction products side by side.\n",
    "    \n",
    "    Args:\n",
    "        precursors: SMILES of reactants\n",
    "        predicted: Predicted product SMILES\n",
    "        expected: Ground truth product SMILES\n",
    "        title: Display title\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    pred_canonical = canonicalize_smiles(predicted)\n",
    "    exp_canonical = canonicalize_smiles(expected)\n",
    "    is_correct = pred_canonical == exp_canonical\n",
    "    \n",
    "    status_color = GOMES_COLORS['success'] if is_correct else GOMES_COLORS['coral']\n",
    "    status_text = \"CORRECT\" if is_correct else \"INCORRECT\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {status_color}; padding: 15px; margin: 10px 0; border-radius: 8px;\">\n",
    "        <h3 style=\"color: {GOMES_COLORS['navy']};\">{title}</h3>\n",
    "        <p><strong>Status:</strong> <span style=\"color: {status_color}; font-weight: bold;\">{status_text}</span></p>\n",
    "        <p><strong>Reactants:</strong> <code>{precursors}</code></p>\n",
    "        <p><strong>Predicted:</strong> <code>{predicted}</code></p>\n",
    "        <p><strong>Expected:</strong> <code>{expected}</code></p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Draw the predicted reaction\n",
    "    rxn_smiles = f\"{precursors}>>{predicted}\"\n",
    "    try:\n",
    "        display(SVG(draw_chemical_reaction(rxn_smiles)))\n",
    "    except:\n",
    "        print(\"(Could not render reaction)\")\n",
    "\n",
    "# Show some examples from our evaluation\n",
    "print(\"Sample Predictions from Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show correct predictions\n",
    "correct_samples = eval_results[eval_results['rank'] == 1].head(3)\n",
    "for _, row in correct_samples.iterrows():\n",
    "    draw_reaction_comparison(\n",
    "        row['precursors'],\n",
    "        row['pred_1'],\n",
    "        row['target_canonical'],\n",
    "        \"Correct Prediction\"\n",
    "    )\n",
    "\n",
    "# Show incorrect predictions\n",
    "incorrect_samples = eval_results[eval_results['rank'] == 0].head(2)\n",
    "for _, row in incorrect_samples.iterrows():\n",
    "    draw_reaction_comparison(\n",
    "        row['precursors'],\n",
    "        row['pred_1'],\n",
    "        row['target_canonical'],\n",
    "        \"Incorrect Prediction\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "### 4.2 Error Analysis and Debugging\n",
    "\n",
    "Understanding why predictions fail is crucial for improving models and understanding their limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Error Analysis\n",
    "\n",
    "def analyze_prediction_errors(results_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze types of prediction errors.\n",
    "    \n",
    "    Categories:\n",
    "    - Invalid SMILES: Model output couldn't be parsed\n",
    "    - Wrong product: Valid SMILES but incorrect\n",
    "    - Partial match: Correct in later predictions (Top-2 to Top-5)\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from evaluate_predictions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with error statistics\n",
    "    \"\"\"\n",
    "    n_total = len(results_df)\n",
    "    \n",
    "    # Categorize errors\n",
    "    correct_top1 = (results_df['rank'] == 1).sum()\n",
    "    correct_top5 = (results_df['rank'] > 0).sum()\n",
    "    invalid_smiles = (~results_df['pred_1_valid']).sum()\n",
    "    wrong_but_valid = (results_df['rank'] == 0) & (results_df['pred_1_valid'])\n",
    "    \n",
    "    analysis = {\n",
    "        'total_reactions': n_total,\n",
    "        'correct_top1': correct_top1,\n",
    "        'correct_top1_pct': correct_top1 / n_total * 100,\n",
    "        'correct_top5': correct_top5,\n",
    "        'correct_top5_pct': correct_top5 / n_total * 100,\n",
    "        'invalid_smiles': invalid_smiles,\n",
    "        'invalid_smiles_pct': invalid_smiles / n_total * 100,\n",
    "        'wrong_but_valid': wrong_but_valid.sum(),\n",
    "        'wrong_but_valid_pct': wrong_but_valid.sum() / n_total * 100,\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Run error analysis\n",
    "error_analysis = analyze_prediction_errors(eval_results)\n",
    "\n",
    "print(\"Error Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total reactions evaluated: {error_analysis['total_reactions']}\")\n",
    "print(f\"\")\n",
    "print(f\"Correct (Top-1): {error_analysis['correct_top1']} ({error_analysis['correct_top1_pct']:.1f}%)\")\n",
    "print(f\"Correct (Top-5): {error_analysis['correct_top5']} ({error_analysis['correct_top5_pct']:.1f}%)\")\n",
    "print(f\"Invalid SMILES: {error_analysis['invalid_smiles']} ({error_analysis['invalid_smiles_pct']:.1f}%)\")\n",
    "print(f\"Wrong but valid: {error_analysis['wrong_but_valid']} ({error_analysis['wrong_but_valid_pct']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Common Failure Patterns\n",
    "\n",
    "print(\"\"\"\n",
    "Common Failure Patterns in Reaction Prediction\n",
    "===============================================\n",
    "\n",
    "1. STEREOCHEMISTRY ERRORS\n",
    "   - Model predicts correct connectivity but wrong stereochemistry\n",
    "   - Often seen in reactions involving chiral centers\n",
    "   - The USPTO dataset lacks stereochemistry, so models may struggle\n",
    "\n",
    "2. REGIOSELECTIVITY ERRORS\n",
    "   - Model predicts reaction at wrong position on molecule\n",
    "   - Common for aromatic substitution reactions\n",
    "   - Example: ortho vs para product in electrophilic substitution\n",
    "\n",
    "3. INCOMPLETE REACTIONS\n",
    "   - Model predicts only partial transformation\n",
    "   - May miss side products or byproducts\n",
    "   - Common for multi-step reactions treated as single step\n",
    "\n",
    "4. OVER-GENERALIZATION\n",
    "   - Model predicts common reaction type inappropriately\n",
    "   - May suggest Suzuki coupling when conditions don't support it\n",
    "   - Result of training data bias\n",
    "\n",
    "5. INVALID SMILES\n",
    "   - Model generates syntactically invalid output\n",
    "   - Often happens with very long molecules\n",
    "   - May indicate out-of-distribution inputs\n",
    "\n",
    "Debugging Tips:\n",
    "   - Always validate output SMILES with RDKit\n",
    "   - Check if reactants contain unusual functional groups\n",
    "   - Consider whether reaction type was in training data\n",
    "   - Use beam search (multiple predictions) to see alternatives\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='appendix-a'></a>\n",
    "## Appendix A: Legacy OpenNMT-py Approach (Reference Only)\n",
    "\n",
    "The original 2022 notebook used OpenNMT-py for training Molecular Transformers. While this approach is now deprecated, understanding the architecture is still valuable.\n",
    "\n",
    "**Why OpenNMT-py is no longer recommended:**\n",
    "\n",
    "1. **Maintenance Mode**: As of July 2024, OpenNMT-py is no longer actively developed. The successor project is [Eole](https://github.com/eole-nlp/eole).\n",
    "\n",
    "2. **Dependency Issues**: The `pyonmttok` tokenizer doesn't support Python 3.12 (Google Colab's current version).\n",
    "\n",
    "3. **Better Alternatives**: HuggingFace Transformers offers better ecosystem integration, more models, and active development.\n",
    "\n",
    "For historical reference, the key OpenNMT-py commands were:\n",
    "\n",
    "```bash\n",
    "# Build vocabulary\n",
    "onmt_build_vocab -config config.yaml -n_sample -1\n",
    "\n",
    "# Train model\n",
    "onmt_train -config config.yaml -seed 42 -gpu_ranks 0 ...\n",
    "\n",
    "# Translate (predict)\n",
    "onmt_translate -model model.pt -src test_src.txt -output predictions.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix-b'></a>\n",
    "## Appendix B: Publications and Resources\n",
    "\n",
    "### Core Papers\n",
    "\n",
    "**Molecular Transformer:**\n",
    "- Schwaller, P. et al. \"Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\" *ACS Central Science* (2019) [Link](https://pubs.acs.org/doi/10.1021/acscentsci.9b00576)\n",
    "\n",
    "**ReactionT5:**\n",
    "- Sagawa, T. & Kojima, R. \"ReactionT5: a pre-trained transformer model for accurate chemical reaction prediction with limited data\" *Journal of Cheminformatics* (2025) [Link](https://doi.org/10.1186/s13321-025-01075-4)\n",
    "\n",
    "**RXNMapper:**\n",
    "- Schwaller, P. et al. \"Extraction of organic chemistry grammar from unsupervised learning of chemical reactions\" *Science Advances* (2021) [Link](https://www.science.org/doi/10.1126/sciadv.abe4166)\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "**Tutorials and Blogs:**\n",
    "- [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) - Visual explanation of transformer architecture\n",
    "- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) - Code walkthrough\n",
    "\n",
    "**Tools and Datasets:**\n",
    "- [Open Reaction Database (ORD)](https://open-reaction-database.org/) - Large-scale reaction data\n",
    "- [IBM RXN for Chemistry](https://rxn.res.ibm.com) - Production API\n",
    "- [RDKit](https://www.rdkit.org/) - Cheminformatics toolkit\n",
    "\n",
    "**Review Papers:**\n",
    "- Schwaller, P. \"Machine Intelligence for Chemical Reaction Space\" *WIREs Computational Molecular Science* (2022) [Link](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wcms.1604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Session Summary\n",
    "\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "                    SESSION SUMMARY: REACTION PREDICTION\n",
    "================================================================================\n",
    "\n",
    "Key Takeaways:\n",
    "\n",
    "1. SMILES as Chemical Language\n",
    "   - Molecules and reactions can be represented as text strings\n",
    "   - Canonicalization ensures consistent representation\n",
    "   - Atom-wise tokenization preserves chemical meaning\n",
    "\n",
    "2. Transformer Models for Chemistry\n",
    "   - Treat reaction prediction as sequence-to-sequence translation\n",
    "   - Self-attention captures long-range dependencies in molecules\n",
    "   - Pre-training on large datasets enables transfer learning\n",
    "\n",
    "3. ReactionT5v2 Advantages\n",
    "   - Pre-trained on diverse Open Reaction Database\n",
    "   - Easy fine-tuning for specialized applications\n",
    "   - Works out-of-the-box on Google Colab\n",
    "\n",
    "4. Practical Considerations\n",
    "   - Always validate output SMILES\n",
    "   - Use beam search for multiple predictions\n",
    "   - Data augmentation improves generalization\n",
    "   - Consider API services for production use\n",
    "\n",
    "Next Steps:\n",
    "   - Try fine-tuning on your own reaction dataset\n",
    "   - Explore retrosynthesis for synthesis planning\n",
    "   - Integrate with reaction fingerprints (RXNFP/DRFP)\n",
    "   - Investigate yield prediction capabilities\n",
    "\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: Clean up GPU memory\n",
    "import gc\n",
    "\n",
    "# Clean up models to free memory\n",
    "if 'forward_predictor' in dir():\n",
    "    del forward_predictor\n",
    "if 'retro_predictor' in dir():\n",
    "    del retro_predictor\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory cleared. Current usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Session complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
