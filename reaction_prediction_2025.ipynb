{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Reaction Prediction with Transformers (2025 Edition)\n",
    "\n",
    "![Molecular Transformer Animation](https://pubs.acs.org/cms/10.1021/acscentsci.9b00576/asset/images/medium/oc9b00576_0009.gif)\n",
    "<center><b>Figure 1:</b> SMILES-to-SMILES translation with the Molecular Transformer</center>\n",
    "\n",
    "---\n",
    "\n",
    "## Course: 06-731 Molecular Machine Learning\n",
    "**Original lecture by:** Philippe Schwaller (IBM Research / EPFL)  \n",
    "**Updated for 2025 by:** Gomes Group, Carnegie Mellon University\n",
    "\n",
    "---\n",
    "\n",
    "## What's New in This Version?\n",
    "\n",
    "This notebook is an updated version of the 2022 \"Digital Molecular Design Studio\" notebook on Chemical Language Models. Key changes include:\n",
    "\n",
    "| Component | 2022 Version | 2025 Version |\n",
    "|-----------|--------------|---------------|\n",
    "| **Framework** | OpenNMT-py 2.2.0 | HuggingFace Transformers (ReactionT5v2) |\n",
    "| **Model** | Custom Molecular Transformer | Pre-trained ReactionT5v2 |\n",
    "| **Python** | 3.6-3.8 | 3.10-3.12 |\n",
    "| **Training** | From scratch (24+ hours) | Fine-tuning (minutes) or inference-only |\n",
    "| **Atom Mapping** | Not included | RXNMapper integration |\n",
    "| **API Access** | Not available | rxn4chemistry (IBM RXN) |\n",
    "\n",
    "### Why the Change?\n",
    "\n",
    "1. **OpenNMT-py is deprecated** - The project announced it's \"no longer actively supported\" as of July 2024, with [Eole](https://github.com/eole-nlp/eole) as the successor.\n",
    "2. **pyonmttok dependency issues** - The tokenizer package fails on Python 3.12 (Google Colab's current version).\n",
    "3. **Better alternatives exist** - ReactionT5v2 offers state-of-the-art performance with easier setup.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Part 1: Setup and Foundations\n",
    "- [1.1 Environment Setup](#1.1)\n",
    "- [1.2 SMILES Representation Review](#1.2)\n",
    "- [1.3 Tokenization for Chemical Language Models](#1.3)\n",
    "\n",
    "### Part 2: Reaction Prediction with ReactionT5v2\n",
    "- [2.1 Loading Pre-trained Models](#2.1)\n",
    "- [2.2 Forward Reaction Prediction](#2.2)\n",
    "- [2.3 Batch Predictions and Evaluation](#2.3)\n",
    "- [2.4 Retrosynthesis Prediction](#2.4)\n",
    "\n",
    "### Part 3: Advanced Topics\n",
    "- [3.1 Atom Mapping with RXNMapper](#3.1)\n",
    "- [3.2 IBM RXN for Chemistry API](#3.2)\n",
    "- [3.3 Data Augmentation for SMILES](#3.3)\n",
    "- [3.4 Fine-tuning on Custom Datasets](#3.4)\n",
    "\n",
    "### Part 4: Visualization and Analysis\n",
    "- [4.1 Drawing Chemical Reactions](#4.1)\n",
    "- [4.2 Error Analysis and Debugging](#4.2)\n",
    "\n",
    "### Appendix\n",
    "- [A. Legacy OpenNMT-py Approach (Reference Only)](#appendix-a)\n",
    "- [B. Publications and Resources](#appendix-b)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Foundations\n",
    "\n",
    "<a id='1.1'></a>\n",
    "### 1.1 Environment Setup\n",
    "\n",
    "We'll install the necessary packages for this notebook. The installation is designed to work on Google Colab (Python 3.12) and local conda environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Environment Detection and Package Installation\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Core packages for chemical reaction prediction\n",
    "PACKAGES = [\n",
    "    \"rdkit\",                    # Cheminformatics toolkit\n",
    "    \"torch\",                    # PyTorch (usually pre-installed in Colab)\n",
    "    \"transformers>=4.40.0\",     # HuggingFace Transformers\n",
    "    \"tokenizers>=0.19.1\",       # Fast tokenizers\n",
    "    \"sentencepiece\",            # Tokenizer backend\n",
    "    \"accelerate\",               # Training acceleration\n",
    "    \"datasets\",                 # HuggingFace datasets\n",
    "    \"pandas\",                   # Data manipulation\n",
    "    \"gdown\",                    # Google Drive downloads\n",
    "    \"tqdm\",                     # Progress bars\n",
    "    \"plotly\",                   # Interactive visualization\n",
    "]\n",
    "\n",
    "def install_packages(packages):\n",
    "    \"\"\"Install packages with progress feedback.\"\"\"\n",
    "    for pkg in packages:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "    print(\"\\n[SUCCESS] All packages installed!\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    install_packages(PACKAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Configure Environment\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# RDKit imports\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem, rdChemReactions\n",
    "from rdkit.Chem.Draw import rdMolDraw2D, IPythonConsole\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# HuggingFace imports\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Display settings\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "RDLogger.DisableLog('rdApp.*')  # Suppress RDKit warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Check GPU availability\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {DEVICE}\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(f\"\\nRDKit version: {Chem.rdBase.rdkitVersion}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Gomes Group Color Palette for Visualizations\n",
    "# Professional styling consistent with Gomes Group publications\n",
    "\n",
    "GOMES_COLORS = {\n",
    "    'teal': '#00D9FF',      # Primary accent\n",
    "    'coral': '#FF6B6B',     # Secondary accent / errors\n",
    "    'navy': '#0A1628',      # Dark background\n",
    "    'slate': '#2D3748',     # Text\n",
    "    'success': '#48BB78',   # Correct predictions\n",
    "    'warning': '#ECC94B',   # Warnings\n",
    "    'light_bg': '#F7FAFC',  # Light background\n",
    "}\n",
    "\n",
    "# Plotly template for consistent styling\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "GOMES_TEMPLATE = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        font=dict(family=\"Helvetica Neue, Arial, sans-serif\", size=14, color=GOMES_COLORS['slate']),\n",
    "        plot_bgcolor=GOMES_COLORS['light_bg'],\n",
    "        paper_bgcolor='white',\n",
    "        colorway=[GOMES_COLORS['teal'], GOMES_COLORS['coral'], GOMES_COLORS['success'], GOMES_COLORS['warning']],\n",
    "        title=dict(font=dict(size=20, color=GOMES_COLORS['navy'])),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Gomes Group styling configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 SMILES Representation Review\n",
    "\n",
    "**SMILES (Simplified Molecular Input Line Entry System)** is a line notation for representing molecules as text strings. For reaction prediction, we treat chemical reactions as a translation problem:\n",
    "\n",
    "```\n",
    "Reactants.Reagents >> Products\n",
    "```\n",
    "\n",
    "Key concepts:\n",
    "- **Atoms**: C, N, O, S, etc. (uppercase = aromatic, lowercase = aromatic ring member)\n",
    "- **Bonds**: Single (implicit or `-`), double (`=`), triple (`#`)\n",
    "- **Rings**: Numbers indicate ring closures (e.g., `C1CCCCC1` = cyclohexane)\n",
    "- **Branches**: Parentheses for branching (e.g., `CC(C)C` = isobutane)\n",
    "- **Stereochemistry**: `@`, `@@` for chirality; `/`, `\\` for cis/trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: SMILES Examples and Canonicalization\n",
    "\n",
    "def canonicalize_smiles(smiles: str, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert a SMILES string to its canonical form.\n",
    "    \n",
    "    Canonicalization ensures that the same molecule always has the same SMILES,\n",
    "    regardless of how it was originally written. This is crucial for:\n",
    "    1. Comparing predictions to ground truth\n",
    "    2. Removing duplicates from datasets\n",
    "    3. Ensuring reproducibility\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input SMILES string\n",
    "        verbose: Print warning for invalid SMILES\n",
    "    \n",
    "    Returns:\n",
    "        Canonical SMILES or empty string if invalid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"Warning: '{smiles}' could not be parsed as a valid molecule.\")\n",
    "            return ''\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing '{smiles}': {e}\")\n",
    "        return ''\n",
    "\n",
    "# Demonstrate canonicalization\n",
    "examples = [\n",
    "    (\"C(C)O\", \"Ethanol - different atom ordering\"),\n",
    "    (\"OCC\", \"Ethanol - starting from oxygen\"),\n",
    "    (\"CCO\", \"Ethanol - canonical form\"),\n",
    "    (\"c1ccccc1\", \"Benzene - aromatic notation\"),\n",
    "    (\"C1=CC=CC=C1\", \"Benzene - Kekule notation\"),\n",
    "]\n",
    "\n",
    "print(\"SMILES Canonicalization Examples:\")\n",
    "print(\"-\" * 60)\n",
    "for smiles, description in examples:\n",
    "    canonical = canonicalize_smiles(smiles)\n",
    "    print(f\"{smiles:20} -> {canonical:20} ({description})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualize molecules from SMILES\n",
    "\n",
    "def draw_molecules_grid(smiles_list: List[str], labels: Optional[List[str]] = None, \n",
    "                        mols_per_row: int = 4, img_size: Tuple[int, int] = (250, 200)):\n",
    "    \"\"\"\n",
    "    Draw a grid of molecules from SMILES strings.\n",
    "    \n",
    "    Args:\n",
    "        smiles_list: List of SMILES strings\n",
    "        labels: Optional labels for each molecule\n",
    "        mols_per_row: Number of molecules per row\n",
    "        img_size: Size of each molecule image\n",
    "    \n",
    "    Returns:\n",
    "        RDKit grid image\n",
    "    \"\"\"\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "    if labels is None:\n",
    "        labels = smiles_list\n",
    "    \n",
    "    return Draw.MolsToGridImage(\n",
    "        mols, \n",
    "        molsPerRow=mols_per_row, \n",
    "        subImgSize=img_size,\n",
    "        legends=labels\n",
    "    )\n",
    "\n",
    "# Example: Common functional groups in drug molecules\n",
    "drug_motifs = [\n",
    "    (\"c1ccccc1\", \"Benzene\"),\n",
    "    (\"c1ccncc1\", \"Pyridine\"),\n",
    "    (\"c1ccc2[nH]ccc2c1\", \"Indole\"),\n",
    "    (\"CC(=O)O\", \"Acetic acid\"),\n",
    "    (\"CC(=O)N\", \"Acetamide\"),\n",
    "    (\"c1ccc(O)cc1\", \"Phenol\"),\n",
    "    (\"c1ccc(N)cc1\", \"Aniline\"),\n",
    "    (\"CC(C)C\", \"Isobutane\"),\n",
    "]\n",
    "\n",
    "smiles_list, labels = zip(*drug_motifs)\n",
    "draw_molecules_grid(list(smiles_list), list(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Tokenization for Chemical Language Models\n",
    "\n",
    "Unlike natural language, SMILES requires **atom-wise tokenization** to preserve chemical meaning. We use a regex pattern that recognizes:\n",
    "\n",
    "- Multi-character elements (Br, Cl)\n",
    "- Bracketed atoms ([NH2], [Fe+2])\n",
    "- Ring numbers (including extended %XX notation)\n",
    "- Stereochemistry markers\n",
    "- Special symbols (reaction arrow `>>`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: SMILES Tokenization\n",
    "\n",
    "# Regex pattern from the original Molecular Transformer paper\n",
    "SMI_REGEX_PATTERN = r\"(\\%\\([0-9]{3}\\)|\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\||\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "\n",
    "def smiles_tokenizer(smiles: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES string into space-separated tokens.\n",
    "    \n",
    "    This tokenization preserves chemical meaning by keeping:\n",
    "    - Multi-character elements together (Br, Cl)\n",
    "    - Bracketed atoms as single tokens ([NH2])\n",
    "    - Ring numbers as single tokens\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input SMILES string\n",
    "    \n",
    "    Returns:\n",
    "        Space-separated tokenized SMILES\n",
    "    \"\"\"\n",
    "    regex = re.compile(SMI_REGEX_PATTERN)\n",
    "    tokens = regex.findall(smiles)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def detokenize_smiles(tokenized: str) -> str:\n",
    "    \"\"\"Convert tokenized SMILES back to standard SMILES.\"\"\"\n",
    "    return tokenized.replace(' ', '')\n",
    "\n",
    "# Demonstration\n",
    "test_smiles = [\n",
    "    \"CCO\",                                    # Simple: ethanol\n",
    "    \"CC(=O)Oc1ccccc1C(=O)O\",                  # Aspirin\n",
    "    \"[NH2]c1ccccc1Br\",                        # Bracketed atoms\n",
    "    \"CC.CC>>CCCC\",                            # Reaction SMILES\n",
    "    \"C[C@@H](O)CC\",                           # Stereochemistry\n",
    "]\n",
    "\n",
    "print(\"SMILES Tokenization Examples:\")\n",
    "print(\"=\" * 70)\n",
    "for smi in test_smiles:\n",
    "    tokenized = smiles_tokenizer(smi)\n",
    "    n_tokens = len(tokenized.split())\n",
    "    print(f\"\\nOriginal ({len(smi)} chars):\")\n",
    "    print(f\"  {smi}\")\n",
    "    print(f\"Tokenized ({n_tokens} tokens):\")\n",
    "    print(f\"  {tokenized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Reaction Prediction with ReactionT5v2\n",
    "\n",
    "<a id='2.1'></a>\n",
    "### 2.1 Loading Pre-trained Models\n",
    "\n",
    "**ReactionT5v2** is a T5 model pre-trained on the [Open Reaction Database (ORD)](https://github.com/open-reaction-database/ord-data), which contains millions of diverse chemical reactions. Unlike models trained on narrow patent datasets, ReactionT5 offers:\n",
    "\n",
    "- **Greater generalizability** across reaction types\n",
    "- **State-of-the-art performance** on standard benchmarks\n",
    "- **Easy fine-tuning** for specialized applications\n",
    "\n",
    "Available models on [HuggingFace](https://huggingface.co/collections/sagawa/reactiont5-67dbe0550cbb6886a85e348b):\n",
    "- `sagawa/ReactionT5v2-forward` - Forward reaction prediction (reactants -> products)\n",
    "- `sagawa/ReactionT5v2-retrosynthesis` - Retrosynthesis (products -> reactants)\n",
    "- `sagawa/ReactionT5v2-yield` - Yield prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load ReactionT5v2 Forward Model\n",
    "\n",
    "class ReactionT5Predictor:\n",
    "    \"\"\"\n",
    "    Wrapper class for ReactionT5v2 models providing easy-to-use prediction methods.\n",
    "    \n",
    "    This class handles:\n",
    "    - Model and tokenizer loading\n",
    "    - Input formatting (REACTANT:...REAGENT:... format)\n",
    "    - Batch prediction with beam search\n",
    "    - Output post-processing and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sagawa/ReactionT5v2-forward\", device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with a pre-trained model.\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model identifier\n",
    "            device: 'cuda' or 'cpu' (auto-detected if None)\n",
    "        \"\"\"\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        \n",
    "        # Load tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "    \n",
    "    def format_input(self, reactants: str, reagents: str = \" \") -> str:\n",
    "        \"\"\"\n",
    "        Format input for ReactionT5 models.\n",
    "        \n",
    "        Expected format: \"REACTANT:{smiles}REAGENT:{smiles}\"\n",
    "        If no reagents, use a space as placeholder.\n",
    "        \n",
    "        Args:\n",
    "            reactants: SMILES of reactants (concatenated with '.')\n",
    "            reagents: SMILES of reagents/catalysts/solvents (or ' ')\n",
    "        \n",
    "        Returns:\n",
    "            Formatted input string\n",
    "        \"\"\"\n",
    "        return f\"REACTANT:{reactants}REAGENT:{reagents}\"\n",
    "    \n",
    "    def predict(self, reactants: str, reagents: str = \" \", \n",
    "                num_beams: int = 5, num_return_sequences: int = 5,\n",
    "                max_length: int = 200) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict products for a single reaction.\n",
    "        \n",
    "        Args:\n",
    "            reactants: SMILES of reactants\n",
    "            reagents: SMILES of reagents (default: ' ' for none)\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Number of predictions to return\n",
    "            max_length: Maximum output sequence length\n",
    "        \n",
    "        Returns:\n",
    "            List of dicts with 'smiles', 'canonical', 'valid', 'score' keys\n",
    "        \"\"\"\n",
    "        # Format and tokenize input\n",
    "        input_text = self.format_input(reactants, reagents)\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                max_length=max_length,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "            )\n",
    "        \n",
    "        # Decode and validate predictions\n",
    "        results = []\n",
    "        for seq in outputs.sequences:\n",
    "            pred_smiles = self.tokenizer.decode(seq, skip_special_tokens=True)\n",
    "            pred_smiles = pred_smiles.replace(' ', '').rstrip('.')\n",
    "            canonical = canonicalize_smiles(pred_smiles)\n",
    "            \n",
    "            results.append({\n",
    "                'smiles': pred_smiles,\n",
    "                'canonical': canonical,\n",
    "                'valid': canonical != '',\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, reactions: List[Dict], batch_size: int = 16,\n",
    "                      num_beams: int = 5, num_return_sequences: int = 5) -> List[List[Dict]]:\n",
    "        \"\"\"\n",
    "        Batch prediction for multiple reactions.\n",
    "        \n",
    "        Args:\n",
    "            reactions: List of dicts with 'reactants' and optionally 'reagents' keys\n",
    "            batch_size: Batch size for inference\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Predictions per reaction\n",
    "        \n",
    "        Returns:\n",
    "            List of prediction lists (one per input reaction)\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(reactions), batch_size), desc=\"Predicting\"):\n",
    "            batch = reactions[i:i+batch_size]\n",
    "            \n",
    "            # Format inputs\n",
    "            input_texts = [\n",
    "                self.format_input(r['reactants'], r.get('reagents', ' '))\n",
    "                for r in batch\n",
    "            ]\n",
    "            \n",
    "            inputs = self.tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    num_beams=num_beams,\n",
    "                    num_return_sequences=num_return_sequences,\n",
    "                    max_length=200,\n",
    "                )\n",
    "            \n",
    "            # Decode outputs\n",
    "            decoded = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            \n",
    "            # Group by input reaction\n",
    "            for j in range(len(batch)):\n",
    "                start_idx = j * num_return_sequences\n",
    "                end_idx = start_idx + num_return_sequences\n",
    "                \n",
    "                preds = []\n",
    "                for pred in decoded[start_idx:end_idx]:\n",
    "                    pred = pred.replace(' ', '').rstrip('.')\n",
    "                    canonical = canonicalize_smiles(pred)\n",
    "                    preds.append({\n",
    "                        'smiles': pred,\n",
    "                        'canonical': canonical,\n",
    "                        'valid': canonical != '',\n",
    "                    })\n",
    "                all_results.append(preds)\n",
    "        \n",
    "        return all_results\n",
    "\n",
    "# Initialize the predictor\n",
    "print(\"Initializing ReactionT5v2 Forward Predictor...\")\n",
    "print(\"(This may take a moment to download the model)\")\n",
    "print()\n",
    "\n",
    "forward_predictor = ReactionT5Predictor(\"sagawa/ReactionT5v2-forward\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### 2.2 Forward Reaction Prediction\n",
    "\n",
    "Let's test the model on some example reactions. We'll predict products from reactants and reagents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Single Reaction Prediction Examples\n",
    "\n",
    "# Example reactions with known products\n",
    "test_reactions = [\n",
    "    {\n",
    "        \"name\": \"Esterification (Fischer)\",\n",
    "        \"reactants\": \"CC(=O)O.CCO\",  # Acetic acid + Ethanol\n",
    "        \"reagents\": \" \",  # Acid catalyst (implicit)\n",
    "        \"expected\": \"CCOC(C)=O\",  # Ethyl acetate\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Suzuki Coupling\",\n",
    "        \"reactants\": \"Brc1ccccc1.OB(O)c1ccccc1\",  # Bromobenzene + Phenylboronic acid\n",
    "        \"reagents\": \"[Pd]\",  # Palladium catalyst\n",
    "        \"expected\": \"c1ccc(-c2ccccc2)cc1\",  # Biphenyl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Amide Formation\",\n",
    "        \"reactants\": \"CC(=O)O.NCC\",  # Acetic acid + Ethylamine\n",
    "        \"reagents\": \" \",\n",
    "        \"expected\": \"CCNC(C)=O\",  # N-ethylacetamide\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Grignard Addition\",\n",
    "        \"reactants\": \"CC=O.[Mg]Br\",  # Acetaldehyde + MgBr\n",
    "        \"reagents\": \"CCCC\",  # Butyl (as Grignard)\n",
    "        \"expected\": \"CCCCC(C)O\",  # 2-hexanol\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Forward Reaction Prediction Examples\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for rxn in test_reactions:\n",
    "    print(f\"\\n{rxn['name']}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Reactants: {rxn['reactants']}\")\n",
    "    print(f\"Reagents:  {rxn['reagents']}\")\n",
    "    print(f\"Expected:  {rxn['expected']}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = forward_predictor.predict(\n",
    "        rxn['reactants'], \n",
    "        rxn['reagents'],\n",
    "        num_beams=5,\n",
    "        num_return_sequences=3\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPredictions:\")\n",
    "    expected_canonical = canonicalize_smiles(rxn['expected'])\n",
    "    \n",
    "    for i, pred in enumerate(predictions, 1):\n",
    "        status = \"[CORRECT]\" if pred['canonical'] == expected_canonical else \"\"\n",
    "        valid = \"valid\" if pred['valid'] else \"INVALID\"\n",
    "        print(f\"  {i}. {pred['canonical']:40} ({valid}) {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualize a Predicted Reaction\n",
    "from IPython.display import SVG, display, HTML\n",
    "\n",
    "def draw_chemical_reaction(rxn_smiles: str, highlight_by_reactant: bool = True,\n",
    "                           use_smiles: bool = True, width: int = 800, height: int = 250) -> str:\n",
    "    \"\"\"\n",
    "    Draw a chemical reaction from SMILES.\n",
    "    \n",
    "    Args:\n",
    "        rxn_smiles: Reaction SMILES (format: reactants>>products)\n",
    "        highlight_by_reactant: Color atoms by which reactant they came from\n",
    "        use_smiles: Parse as SMILES (True) or SMARTS (False)\n",
    "        width: Image width\n",
    "        height: Image height\n",
    "    \n",
    "    Returns:\n",
    "        SVG string of the reaction drawing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rxn = rdChemReactions.ReactionFromSmarts(rxn_smiles, useSmiles=use_smiles)\n",
    "        d2d = rdMolDraw2D.MolDraw2DSVG(width, height)\n",
    "        d2d.drawOptions().annotationFontScale = 1.2\n",
    "        d2d.DrawReaction(rxn, highlightByReactant=highlight_by_reactant)\n",
    "        d2d.FinishDrawing()\n",
    "        return d2d.GetDrawingText()\n",
    "    except Exception as e:\n",
    "        return f\"<p>Error drawing reaction: {e}</p>\"\n",
    "\n",
    "# Draw the first test reaction with its prediction\n",
    "rxn = test_reactions[0]\n",
    "predictions = forward_predictor.predict(rxn['reactants'], rxn['reagents'], num_return_sequences=1)\n",
    "pred_smiles = predictions[0]['canonical']\n",
    "\n",
    "print(f\"Reaction: {rxn['name']}\")\n",
    "print(f\"Input: {rxn['reactants']}\")\n",
    "print(f\"Predicted Product: {pred_smiles}\")\n",
    "print(f\"Expected Product: {rxn['expected']}\")\n",
    "\n",
    "rxn_smiles = f\"{rxn['reactants']}>>{pred_smiles}\"\n",
    "display(SVG(draw_chemical_reaction(rxn_smiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### 2.3 Batch Predictions and Evaluation\n",
    "\n",
    "Now let's evaluate the model on a larger dataset. We'll download a subset of the USPTO dataset and compute standard metrics (Top-1, Top-3, Top-5 accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Download USPTO Dataset Subset\n",
    "import gdown\n",
    "\n",
    "def download_uspto_data(data_dir: str = \"USPTO_480k\") -> None:\n",
    "    \"\"\"\n",
    "    Download USPTO 480k reaction dataset.\n",
    "    \n",
    "    This dataset contains ~480,000 reactions from US patents,\n",
    "    split into train/val/test sets.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Google Drive links for USPTO_480k\n",
    "    files = [\n",
    "        (\"https://drive.google.com/uc?id=1RysNBvB2rsMP0Ap9XXi02XiiZkEXCrA8\", \"src-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1CxxcVqtmOmHE2nhmqPFA6bilavzpcIlb\", \"tgt-train.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FFN1nz2yB4VwrpWaBuiBDzFzdX3ONBsy\", \"src-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1pYCjWkYvgp1ZQ78EKQBArOvt_2P1KnmI\", \"tgt-val.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=10t6pHj9yR8Tp3kDvG0KMHl7Bt_TUbQ8W\", \"src-test.txt\"),\n",
    "        (\"https://drive.google.com/uc?id=1FeGuiGuz0chVBRgePMu0pGJA4FVReA-b\", \"tgt-test.txt\"),\n",
    "    ]\n",
    "    \n",
    "    for url, filename in files:\n",
    "        target = os.path.join(data_dir, filename)\n",
    "        if not os.path.exists(target):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            gdown.download(url, target, quiet=False)\n",
    "        else:\n",
    "            print(f\"{filename} already exists.\")\n",
    "\n",
    "def load_uspto_data(data_dir: str = \"USPTO_480k\", split: str = \"val\", \n",
    "                    max_samples: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load USPTO dataset into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Directory containing the data files\n",
    "        split: 'train', 'val', or 'test'\n",
    "        max_samples: Maximum number of samples to load (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with 'precursors' and 'products' columns\n",
    "    \"\"\"\n",
    "    src_file = os.path.join(data_dir, f\"src-{split}.txt\")\n",
    "    tgt_file = os.path.join(data_dir, f\"tgt-{split}.txt\")\n",
    "    \n",
    "    with open(src_file, 'r') as f:\n",
    "        precursors = [line.strip().replace(' ', '') for line in f]\n",
    "    with open(tgt_file, 'r') as f:\n",
    "        products = [line.strip().replace(' ', '') for line in f]\n",
    "    \n",
    "    df = pd.DataFrame({'precursors': precursors, 'products': products})\n",
    "    \n",
    "    if max_samples:\n",
    "        df = df.head(max_samples)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Download and load data\n",
    "print(\"Downloading USPTO 480k dataset...\")\n",
    "download_uspto_data()\n",
    "\n",
    "# For demonstration, we'll use a smaller subset\n",
    "N_EVAL_SAMPLES = 100  # Use 100 samples for quick evaluation\n",
    "val_df = load_uspto_data(split=\"val\", max_samples=N_EVAL_SAMPLES)\n",
    "\n",
    "print(f\"\\nLoaded {len(val_df)} validation reactions\")\n",
    "print(\"\\nSample reactions:\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Evaluate Model on USPTO Validation Set\n",
    "\n",
    "def evaluate_predictions(df: pd.DataFrame, predictor: ReactionT5Predictor,\n",
    "                        n_best: int = 5, batch_size: int = 16) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate model predictions against ground truth.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'precursors' and 'products' columns\n",
    "        predictor: ReactionT5Predictor instance\n",
    "        n_best: Number of predictions per reaction\n",
    "        batch_size: Batch size for inference\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions and evaluation metrics\n",
    "    \"\"\"\n",
    "    # Prepare reactions for batch prediction\n",
    "    reactions = [{'reactants': row['precursors'], 'reagents': ' '} \n",
    "                 for _, row in df.iterrows()]\n",
    "    \n",
    "    # Get predictions\n",
    "    all_predictions = predictor.predict_batch(\n",
    "        reactions, \n",
    "        batch_size=batch_size,\n",
    "        num_beams=n_best,\n",
    "        num_return_sequences=n_best\n",
    "    )\n",
    "    \n",
    "    # Add predictions to DataFrame\n",
    "    results = df.copy()\n",
    "    results['target_canonical'] = results['products'].apply(canonicalize_smiles)\n",
    "    \n",
    "    # Store predictions\n",
    "    for i in range(n_best):\n",
    "        results[f'pred_{i+1}'] = [preds[i]['canonical'] if i < len(preds) else '' \n",
    "                                   for preds in all_predictions]\n",
    "        results[f'pred_{i+1}_valid'] = [preds[i]['valid'] if i < len(preds) else False \n",
    "                                         for preds in all_predictions]\n",
    "    \n",
    "    # Calculate rank of correct prediction\n",
    "    def get_rank(row):\n",
    "        target = row['target_canonical']\n",
    "        for i in range(1, n_best + 1):\n",
    "            if row[f'pred_{i}'] == target:\n",
    "                return i\n",
    "        return 0  # Not found\n",
    "    \n",
    "    results['rank'] = results.apply(get_rank, axis=1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run evaluation (this may take a few minutes)\n",
    "print(f\"Evaluating on {len(val_df)} reactions...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "eval_results = evaluate_predictions(val_df, forward_predictor, n_best=5, batch_size=8)\n",
    "\n",
    "# Calculate metrics\n",
    "n_total = len(eval_results)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for k in [1, 2, 3, 5]:\n",
    "    correct = (eval_results['rank'] > 0) & (eval_results['rank'] <= k)\n",
    "    accuracy = correct.sum() / n_total * 100\n",
    "    print(f\"Top-{k} Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "# Invalid SMILES rate\n",
    "invalid_rate = (~eval_results['pred_1_valid']).sum() / n_total * 100\n",
    "print(f\"\\nInvalid Top-1 SMILES: {invalid_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Visualize Evaluation Results\n",
    "\n",
    "# Create accuracy bar chart\n",
    "accuracies = []\n",
    "for k in [1, 2, 3, 4, 5]:\n",
    "    correct = (eval_results['rank'] > 0) & (eval_results['rank'] <= k)\n",
    "    accuracy = correct.sum() / len(eval_results) * 100\n",
    "    accuracies.append({'k': f'Top-{k}', 'accuracy': accuracy})\n",
    "\n",
    "acc_df = pd.DataFrame(accuracies)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=acc_df['k'],\n",
    "    y=acc_df['accuracy'],\n",
    "    marker_color=GOMES_COLORS['teal'],\n",
    "    text=[f\"{a:.1f}%\" for a in acc_df['accuracy']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=GOMES_TEMPLATE,\n",
    "    title='ReactionT5v2 Accuracy on USPTO Validation Set',\n",
    "    xaxis_title='',\n",
    "    yaxis_title='Accuracy (%)',\n",
    "    yaxis_range=[0, 100],\n",
    "    showlegend=False,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "### 2.4 Retrosynthesis Prediction\n",
    "\n",
    "Retrosynthesis is the reverse problem: given a target product, predict the reactants needed to synthesize it. This is crucial for drug discovery and chemical manufacturing.\n",
    "\n",
    "ReactionT5v2 also provides a retrosynthesis model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Retrosynthesis Predictor\n",
    "\n",
    "class RetrosynthesisPredictor:\n",
    "    \"\"\"\n",
    "    Wrapper for ReactionT5v2 retrosynthesis model.\n",
    "    \n",
    "    Given a target product, predicts possible reactants.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"sagawa/ReactionT5v2-retrosynthesis\", device: str = None):\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        print(f\"Loading retrosynthesis model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(\"Model loaded!\")\n",
    "    \n",
    "    def predict(self, product: str, num_beams: int = 10, \n",
    "                num_return_sequences: int = 5) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Predict reactants for a target product.\n",
    "        \n",
    "        Args:\n",
    "            product: SMILES of target product\n",
    "            num_beams: Beam search width\n",
    "            num_return_sequences: Number of predictions\n",
    "        \n",
    "        Returns:\n",
    "            List of predicted reactant sets\n",
    "        \"\"\"\n",
    "        input_text = f\"PRODUCT:{product}\"\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                max_length=200,\n",
    "            )\n",
    "        \n",
    "        results = []\n",
    "        for seq in outputs:\n",
    "            pred = self.tokenizer.decode(seq, skip_special_tokens=True)\n",
    "            pred = pred.replace(' ', '').rstrip('.')\n",
    "            \n",
    "            # Validate each reactant\n",
    "            reactants = pred.split('.')\n",
    "            valid = all(canonicalize_smiles(r) != '' for r in reactants if r)\n",
    "            \n",
    "            results.append({\n",
    "                'reactants': pred,\n",
    "                'valid': valid,\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Load retrosynthesis model\n",
    "print(\"Loading retrosynthesis model...\")\n",
    "retro_predictor = RetrosynthesisPredictor(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Retrosynthesis Examples\n",
    "\n",
    "# Target molecules for retrosynthesis\n",
    "targets = [\n",
    "    {\n",
    "        \"name\": \"Aspirin\",\n",
    "        \"smiles\": \"CC(=O)Oc1ccccc1C(=O)O\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ibuprofen\",\n",
    "        \"smiles\": \"CC(C)Cc1ccc(C(C)C(=O)O)cc1\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ethyl Acetate\",\n",
    "        \"smiles\": \"CCOC(C)=O\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Retrosynthesis Predictions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\nTarget: {target['name']}\")\n",
    "    print(f\"SMILES: {target['smiles']}\")\n",
    "    \n",
    "    # Show target molecule\n",
    "    mol = Chem.MolFromSmiles(target['smiles'])\n",
    "    display(mol)\n",
    "    \n",
    "    # Get retrosynthesis predictions\n",
    "    predictions = retro_predictor.predict(target['smiles'], num_return_sequences=3)\n",
    "    \n",
    "    print(\"\\nPredicted Reactants:\")\n",
    "    for i, pred in enumerate(predictions, 1):\n",
    "        valid_str = \"valid\" if pred['valid'] else \"INVALID\"\n",
    "        print(f\"  {i}. {pred['reactants']} ({valid_str})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Advanced Topics\n",
    "\n",
    "<a id='3.1'></a>\n",
    "### 3.1 Atom Mapping with RXNMapper\n",
    "\n",
    "Atom mapping shows which atoms in the reactants correspond to which atoms in the products. This is crucial for understanding reaction mechanisms.\n",
    "\n",
    "[RXNMapper](https://github.com/rxn4chemistry/rxnmapper) uses transformer attention to learn atom correspondences without supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Install and Setup RXNMapper\n",
    "\n",
    "# RXNMapper installation (may require specific handling for Colab)\n",
    "try:\n",
    "    from rxnmapper import RXNMapper\n",
    "    RXNMAPPER_AVAILABLE = True\n",
    "    print(\"RXNMapper is available!\")\n",
    "except ImportError:\n",
    "    print(\"Installing RXNMapper...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rxnmapper\"])\n",
    "    \n",
    "    try:\n",
    "        from rxnmapper import RXNMapper\n",
    "        RXNMAPPER_AVAILABLE = True\n",
    "        print(\"RXNMapper installed successfully!\")\n",
    "    except ImportError as e:\n",
    "        RXNMAPPER_AVAILABLE = False\n",
    "        print(f\"RXNMapper installation failed: {e}\")\n",
    "        print(\"This is optional - the notebook will continue without atom mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Atom Mapping Examples\n",
    "\n",
    "if RXNMAPPER_AVAILABLE:\n",
    "    # Initialize RXNMapper\n",
    "    rxn_mapper = RXNMapper()\n",
    "    \n",
    "    # Example reactions for atom mapping\n",
    "    reactions_to_map = [\n",
    "        \"CC(=O)O.CCO>>CCOC(C)=O.O\",  # Esterification\n",
    "        \"Brc1ccccc1.OB(O)c1ccccc1>>c1ccc(-c2ccccc2)cc1\",  # Suzuki coupling\n",
    "        \"c1ccccc1.Cl>>Clc1ccccc1\",  # Chlorination\n",
    "    ]\n",
    "    \n",
    "    print(\"Atom Mapping Examples\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for rxn in reactions_to_map:\n",
    "        print(f\"\\nReaction: {rxn}\")\n",
    "        \n",
    "        # Get atom mapping\n",
    "        result = rxn_mapper.get_attention_guided_atom_maps([rxn])[0]\n",
    "        mapped_rxn = result['mapped_rxn']\n",
    "        confidence = result['confidence']\n",
    "        \n",
    "        print(f\"Mapped:   {mapped_rxn}\")\n",
    "        print(f\"Confidence: {confidence:.3f}\")\n",
    "        \n",
    "        # Draw the mapped reaction\n",
    "        try:\n",
    "            display(SVG(draw_chemical_reaction(mapped_rxn, use_smiles=True)))\n",
    "        except:\n",
    "            print(\"(Could not render reaction image)\")\n",
    "else:\n",
    "    print(\"RXNMapper not available. Skipping atom mapping examples.\")\n",
    "    print(\"You can still use the model for reaction prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "### 3.2 IBM RXN for Chemistry API\n",
    "\n",
    "[IBM RXN for Chemistry](https://rxn.res.ibm.com) provides access to production-grade reaction prediction models through a REST API. This is useful for:\n",
    "\n",
    "- Access to models trained on larger datasets\n",
    "- Production applications\n",
    "- No local GPU required\n",
    "\n",
    "**Note:** You need a free API key from [rxn.res.ibm.com](https://rxn.res.ibm.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: IBM RXN for Chemistry Setup (Optional)\n",
    "\n",
    "# Install rxn4chemistry client\n",
    "try:\n",
    "    from rxn4chemistry import RXN4ChemistryWrapper\n",
    "    RXN4CHEM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rxn4chemistry\"])\n",
    "    try:\n",
    "        from rxn4chemistry import RXN4ChemistryWrapper\n",
    "        RXN4CHEM_AVAILABLE = True\n",
    "    except:\n",
    "        RXN4CHEM_AVAILABLE = False\n",
    "\n",
    "if RXN4CHEM_AVAILABLE:\n",
    "    print(\"rxn4chemistry is available!\")\n",
    "    print(\"\")\n",
    "    print(\"To use IBM RXN for Chemistry:\")\n",
    "    print(\"1. Create a free account at https://rxn.res.ibm.com\")\n",
    "    print(\"2. Get your API key from your profile settings\")\n",
    "    print(\"3. Set it below:\")\n",
    "    print(\"\")\n",
    "    print(\"# Example usage:\")\n",
    "    print(\"# api_key = 'YOUR_API_KEY_HERE'\")\n",
    "    print(\"# rxn = RXN4ChemistryWrapper(api_key=api_key)\")\n",
    "    print(\"# rxn.create_project('my_project')\")\n",
    "    print(\"# rxn.predict_reaction('BrBr.c1ccc2cc3ccccc3cc2c1')\")\n",
    "else:\n",
    "    print(\"rxn4chemistry not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: IBM RXN API Example (requires API key)\n",
    "\n",
    "# Uncomment and fill in your API key to use\n",
    "USE_IBM_RXN = False  # Set to True if you have an API key\n",
    "\n",
    "if USE_IBM_RXN and RXN4CHEM_AVAILABLE:\n",
    "    # Replace with your actual API key\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  \n",
    "    \n",
    "    rxn = RXN4ChemistryWrapper(api_key=api_key)\n",
    "    rxn.create_project('reaction_prediction_demo')\n",
    "    \n",
    "    # Predict a reaction\n",
    "    reactants = \"CC(=O)O.CCO\"  # Acetic acid + Ethanol\n",
    "    result = rxn.predict_reaction(reactants)\n",
    "    \n",
    "    print(f\"Input: {reactants}\")\n",
    "    print(f\"Predicted products: {result}\")\n",
    "else:\n",
    "    print(\"IBM RXN API demo skipped.\")\n",
    "    print(\"Set USE_IBM_RXN = True and provide your API key to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "### 3.3 Data Augmentation for SMILES\n",
    "\n",
    "A key technique for improving chemical language models is **SMILES randomization**. Since the same molecule can be written as many different valid SMILES strings, we can augment training data by generating alternative representations.\n",
    "\n",
    "This teaches the model that different SMILES can represent the same molecule, improving generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: SMILES Randomization Functions\n",
    "\n",
    "def randomize_smiles(smiles: str, random_type: str = \"rotated\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generate a random but equivalent SMILES representation.\n",
    "    \n",
    "    Three randomization strategies:\n",
    "    - 'rotated': Change the starting atom (preserves ring-opening order)\n",
    "    - 'restricted': Shuffle atom order with some constraints\n",
    "    - 'unrestricted': Full random atom ordering\n",
    "    \n",
    "    Args:\n",
    "        smiles: Input canonical SMILES\n",
    "        random_type: Randomization strategy\n",
    "    \n",
    "    Returns:\n",
    "        Randomized SMILES or None if invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None\n",
    "    \n",
    "    if random_type == \"unrestricted\":\n",
    "        # Full random SMILES (most diverse)\n",
    "        return Chem.MolToSmiles(mol, canonical=False, doRandom=True, isomericSmiles=True)\n",
    "    \n",
    "    elif random_type == \"restricted\":\n",
    "        # Random atom order with some constraints\n",
    "        new_atom_order = list(range(mol.GetNumAtoms()))\n",
    "        random.shuffle(new_atom_order)\n",
    "        random_mol = Chem.RenumberAtoms(mol, newOrder=new_atom_order)\n",
    "        return Chem.MolToSmiles(random_mol, canonical=False, isomericSmiles=True)\n",
    "    \n",
    "    elif random_type == \"rotated\":\n",
    "        # Rotate starting atom (least disruptive)\n",
    "        n_atoms = mol.GetNumAtoms()\n",
    "        rotation_index = random.randint(0, n_atoms - 1)\n",
    "        atoms = list(range(n_atoms))\n",
    "        new_order = atoms[rotation_index:] + atoms[:rotation_index]\n",
    "        rotated_mol = Chem.RenumberAtoms(mol, new_order)\n",
    "        return Chem.MolToSmiles(rotated_mol, canonical=False, isomericSmiles=True)\n",
    "    \n",
    "    raise ValueError(f\"Unknown random_type: {random_type}\")\n",
    "\n",
    "# Demonstrate SMILES randomization\n",
    "caffeine = \"Cn1cnc2c1c(=O)n(c(=O)n2C)C\"  # Caffeine\n",
    "canonical = canonicalize_smiles(caffeine)\n",
    "\n",
    "print(f\"Canonical SMILES: {canonical}\")\n",
    "print(\"\\nRandomized versions:\")\n",
    "\n",
    "for rand_type in [\"rotated\", \"restricted\", \"unrestricted\"]:\n",
    "    print(f\"\\n{rand_type.upper()}:\")\n",
    "    unique_smiles = set()\n",
    "    for _ in range(100):\n",
    "        rand_smi = randomize_smiles(canonical, rand_type)\n",
    "        if rand_smi:\n",
    "            unique_smiles.add(rand_smi)\n",
    "    \n",
    "    print(f\"  Generated {len(unique_smiles)} unique SMILES from 100 attempts\")\n",
    "    print(f\"  Examples: {list(unique_smiles)[:3]}\")\n",
    "\n",
    "# Verify all random SMILES canonicalize to the same molecule\n",
    "print(\"\\nValidation: All random SMILES should canonicalize to the same molecule\")\n",
    "test_smiles = [randomize_smiles(canonical, \"unrestricted\") for _ in range(10)]\n",
    "canonicalized = set(canonicalize_smiles(s) for s in test_smiles if s)\n",
    "print(f\"Unique canonical forms: {canonicalized}\")\n",
    "assert len(canonicalized) == 1, \"Error: Different molecules produced!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Data Augmentation for Reaction Datasets\n",
    "\n",
    "def augment_reaction_dataset(df: pd.DataFrame, n_augmentations: int = 1,\n",
    "                              random_type: str = \"rotated\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Augment a reaction dataset with randomized SMILES.\n",
    "    \n",
    "    Each reaction is copied with randomized precursor SMILES.\n",
    "    Products are kept canonical (as targets should be deterministic).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'precursors' and 'products' columns\n",
    "        n_augmentations: Number of augmented copies per reaction\n",
    "        random_type: SMILES randomization strategy\n",
    "    \n",
    "    Returns:\n",
    "        Augmented DataFrame\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting\"):\n",
    "        # Original reaction\n",
    "        augmented_data.append({\n",
    "            'precursors': row['precursors'],\n",
    "            'products': row['products'],\n",
    "            'is_augmented': False\n",
    "        })\n",
    "        \n",
    "        # Augmented copies\n",
    "        for _ in range(n_augmentations):\n",
    "            # Randomize each reactant separately\n",
    "            reactants = row['precursors'].split('.')\n",
    "            rand_reactants = []\n",
    "            for r in reactants:\n",
    "                rand_r = randomize_smiles(r, random_type)\n",
    "                rand_reactants.append(rand_r if rand_r else r)\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'precursors': '.'.join(rand_reactants),\n",
    "                'products': row['products'],\n",
    "                'is_augmented': True\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "# Demonstrate augmentation on a small subset\n",
    "sample_df = val_df.head(5)\n",
    "augmented_df = augment_reaction_dataset(sample_df, n_augmentations=2)\n",
    "\n",
    "print(f\"Original dataset: {len(sample_df)} reactions\")\n",
    "print(f\"Augmented dataset: {len(augmented_df)} reactions\")\n",
    "print(f\"Augmentation factor: {len(augmented_df) / len(sample_df):.1f}x\")\n",
    "print(\"\\nSample augmented data:\")\n",
    "augmented_df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n### 3.4 Fine-tuning on Custom Datasets\n\nWhile ReactionT5v2 performs excellently on general reactions, **fine-tuning** on domain-specific data can significantly improve accuracy for specialized reaction types. Research shows that fine-tuning with as few as **200 reactions** can boost performance dramatically.\n\n**When to fine-tune:**\n- Your reactions are from a specialized domain (e.g., enzymatic, photochemistry, organometallic)\n- You need higher accuracy for specific reaction classes\n- Your reagents/conditions differ significantly from USPTO/ORD data\n- You have proprietary reaction data\n\n**What you'll learn in this section:**\n1. Preparing a custom dataset in the correct format\n2. Using HuggingFace Trainer API for efficient fine-tuning\n3. Training with validation and early stopping\n4. Comparing base model vs fine-tuned model performance\n5. Best practices for small dataset fine-tuning\n\n**Computational requirements:**\n- GPU recommended (T4 or better; runs on free Google Colab)\n- ~10-15 minutes training time for demo dataset\n- ~2 GB GPU memory\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 22: Create Synthetic Fine-tuning Dataset\n",
    "\n",
    "import csv\n",
    "from typing import List, Tuple\n",
    "\n",
    "def create_suzuki_coupling_dataset(n_train: int = 300, n_val: int = 50) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Create a synthetic dataset focused on Suzuki-Miyaura coupling reactions.\n",
    "\n",
    "    This demonstrates fine-tuning on a specific reaction type. In practice,\n",
    "    you would use your own proprietary or domain-specific reaction data.\n",
    "\n",
    "    Suzuki coupling: R-X + R'-B(OH)2 -> R-R' (with Pd catalyst)\n",
    "\n",
    "    Args:\n",
    "        n_train: Number of training examples\n",
    "        n_val: Number of validation examples\n",
    "\n",
    "    Returns:\n",
    "        Paths to train and validation CSV files\n",
    "    \"\"\"\n",
    "\n",
    "    # Template reactions: different aromatic halides + boronic acids\n",
    "    # Format: (halide, boronic_acid, product)\n",
    "    suzuki_templates = [\n",
    "        # Simple couplings\n",
    "        (\"Brc1ccccc1\", \"OB(O)c1ccccc1\", \"c1ccc(-c2ccccc2)cc1\"),  # Bromobenzene + phenylboronic acid\n",
    "        (\"Ic1ccccc1\", \"OB(O)c1ccccc1\", \"c1ccc(-c2ccccc2)cc1\"),  # Iodobenzene variant\n",
    "\n",
    "        # With substituents - electron withdrawing\n",
    "        (\"Brc1ccc(C(F)(F)F)cc1\", \"OB(O)c1ccccc1\", \"FC(F)(F)c1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccc([N+](=O)[O-])cc1\", \"OB(O)c1ccccc1\", \"O=[N+]([O-])c1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccc(C#N)cc1\", \"OB(O)c1ccccc1\", \"N#Cc1ccc(-c2ccccc2)cc1\"),\n",
    "\n",
    "        # With substituents - electron donating\n",
    "        (\"Brc1ccc(OC)cc1\", \"OB(O)c1ccccc1\", \"COc1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccc(N)cc1\", \"OB(O)c1ccccc1\", \"Nc1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccc(C)cc1\", \"OB(O)c1ccccc1\", \"Cc1ccc(-c2ccccc2)cc1\"),\n",
    "\n",
    "        # Different boronic acids\n",
    "        (\"Brc1ccccc1\", \"OB(O)c1ccc(OC)cc1\", \"COc1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccccc1\", \"OB(O)c1ccc(C)cc1\", \"Cc1ccc(-c2ccccc2)cc1\"),\n",
    "        (\"Brc1ccccc1\", \"OB(O)c1ccc(F)cc1\", \"Fc1ccc(-c2ccccc2)cc1\"),\n",
    "\n",
    "        # Heterocycles\n",
    "        (\"Brc1ccncc1\", \"OB(O)c1ccccc1\", \"c1ccc(-c2ccncc2)cc1\"),\n",
    "        (\"Brc1ccccc1\", \"OB(O)c1ccncc1\", \"c1ccc(-c2ccncc2)cc1\"),\n",
    "        (\"Brc1ccc2ccccc2c1\", \"OB(O)c1ccccc1\", \"c1ccc(-c2ccc3ccccc3c2)cc1\"),\n",
    "\n",
    "        # Ortho-substituted\n",
    "        (\"Brc1ccccc1C\", \"OB(O)c1ccccc1\", \"Cc1ccccc1-c1ccccc1\"),\n",
    "        (\"Brc1ccccc1OC\", \"OB(O)c1ccccc1\", \"COc1ccccc1-c1ccccc1\"),\n",
    "\n",
    "        # Meta-substituted\n",
    "        (\"Brc1cccc(C)c1\", \"OB(O)c1ccccc1\", \"Cc1cccc(-c2ccccc2)c1\"),\n",
    "        (\"Brc1cccc(OC)c1\", \"OB(O)c1ccccc1\", \"COc1cccc(-c2ccccc2)c1\"),\n",
    "\n",
    "        # Both rings substituted\n",
    "        (\"Brc1ccc(C)cc1\", \"OB(O)c1ccc(OC)cc1\", \"COc1ccc(-c2ccc(C)cc2)cc1\"),\n",
    "        (\"Brc1ccc(F)cc1\", \"OB(O)c1ccc(Cl)cc1\", \"Fc1ccc(-c2ccc(Cl)cc2)cc1\"),\n",
    "        (\"Brc1ccc(C(F)(F)F)cc1\", \"OB(O)c1ccc(N)cc1\", \"Nc1ccc(-c2ccc(C(F)(F)F)cc2)cc1\"),\n",
    "    ]\n",
    "\n",
    "    # Palladium catalysts and bases commonly used\n",
    "    reagents = [\n",
    "        \"[Pd]\",  # Generic Pd catalyst\n",
    "        \"c1ccc(P(c2ccccc2)c2ccccc2)cc1.[Pd]\",  # Pd(PPh3)\n",
    "        \"[Pd].CC(C)(C)P(C(C)(C)C)C(C)(C)C\",  # Pd(t-Bu3P)\n",
    "    ]\n",
    "\n",
    "    # Generate training data with variation\n",
    "    train_file = \"/tmp/suzuki_train.csv\"\n",
    "    val_file = \"/tmp/suzuki_val.csv\"\n",
    "\n",
    "    def generate_reactions(n_samples: int, seed_offset: int = 0) -> List[Dict]:\n",
    "        \"\"\"Generate n_samples with some randomization.\"\"\"\n",
    "        random.seed(SEED + seed_offset)\n",
    "        reactions = []\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            # Pick a random template\n",
    "            halide, boronic, product = random.choice(suzuki_templates)\n",
    "            reagent = random.choice(reagents)\n",
    "\n",
    "            # Optionally randomize SMILES for augmentation\n",
    "            if random.random() < 0.5:  # 50% chance of randomization\n",
    "                halide = randomize_smiles(halide, \"unrestricted\") or halide\n",
    "                boronic = randomize_smiles(boronic, \"unrestricted\") or boronic\n",
    "\n",
    "            reactions.append({\n",
    "                'REACTANT': f\"{halide}.{boronic}\",\n",
    "                'REAGENT': reagent,\n",
    "                'PRODUCT': product  # Keep product canonical\n",
    "            })\n",
    "\n",
    "        return reactions\n",
    "\n",
    "    # Generate and save training data\n",
    "    train_reactions = generate_reactions(n_train, seed_offset=0)\n",
    "    with open(train_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['REACTANT', 'REAGENT', 'PRODUCT'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(train_reactions)\n",
    "\n",
    "    # Generate and save validation data\n",
    "    val_reactions = generate_reactions(n_val, seed_offset=1000)\n",
    "    with open(val_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['REACTANT', 'REAGENT', 'PRODUCT'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(val_reactions)\n",
    "\n",
    "    print(f\"Created Suzuki coupling dataset:\")\n",
    "    print(f\"  Training:   {train_file} ({n_train} reactions)\")\n",
    "    print(f\"  Validation: {val_file} ({n_val} reactions)\")\n",
    "    print(f\"\\nSample reactions:\")\n",
    "\n",
    "    # Show samples\n",
    "    sample_df = pd.DataFrame(train_reactions[:5])\n",
    "    display(sample_df)\n",
    "\n",
    "    return train_file, val_file\n",
    "\n",
    "# Create the dataset\n",
    "train_csv, val_csv = create_suzuki_coupling_dataset(n_train=300, n_val=50)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 23: Custom Dataset Class for ReactionT5\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReactionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for chemical reaction prediction.\n",
    "\n",
    "    Formats data for T5-style seq2seq learning:\n",
    "    - Input: \"REACTANT:{reactants}REAGENT:{reagents}\"\n",
    "    - Target: \"{products}\"\n",
    "\n",
    "    This class handles:\n",
    "    - Loading data from CSV\n",
    "    - Tokenization\n",
    "    - Padding and truncation\n",
    "    - Attention mask creation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str, tokenizer, max_input_length: int = 150,\n",
    "                 max_target_length: int = 100):\n",
    "        \"\"\"\n",
    "        Initialize dataset.\n",
    "\n",
    "        Args:\n",
    "            csv_path: Path to CSV with REACTANT, REAGENT, PRODUCT columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            max_input_length: Maximum tokens for input sequence\n",
    "            max_target_length: Maximum tokens for target sequence\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} reactions from {csv_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single training example.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with input_ids, attention_mask, and labels\n",
    "        \"\"\"\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Format input\n",
    "        input_text = f\"REACTANT:{row['REACTANT']}REAGENT:{row['REAGENT']}\"\n",
    "        target_text = row['PRODUCT']\n",
    "\n",
    "        # Tokenize input\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Tokenize target\n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Prepare labels (replace padding token id with -100 so it's ignored in loss)\n",
    "        labels = target_encoding['input_ids'].squeeze()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating PyTorch datasets...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sagawa/ReactionT5v2-forward\")\n",
    "\n",
    "train_dataset = ReactionDataset(train_csv, tokenizer, max_input_length=150, max_target_length=100)\n",
    "val_dataset = ReactionDataset(val_csv, tokenizer, max_input_length=150, max_target_length=100)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training:   {len(train_dataset)} examples\")\n",
    "print(f\"  Validation: {len(val_dataset)} examples\")\n",
    "\n",
    "# Show a sample\n",
    "print(f\"\\nSample encoded data:\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"Input shape:     {sample['input_ids'].shape}\")\n",
    "print(f\"Labels shape:    {sample['labels'].shape}\")\n",
    "print(f\"Input tokens:    {sample['input_ids'][:20].tolist()}...\")  # First 20 tokens\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 24: Configure Training with HuggingFace Trainer\n",
    "\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# Load fresh model for fine-tuning\n",
    "print(\"Loading ReactionT5v2-forward model for fine-tuning...\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"sagawa/ReactionT5v2-forward\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "output_dir = \"/tmp/reactiont5_finetuned\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # Training hyperparameters\n",
    "    num_train_epochs=20,  # Will stop early if validation loss doesn't improve\n",
    "    per_device_train_batch_size=16,  # Adjust based on GPU memory\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-4,  # Lower than pre-training (1e-3)\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=50,  # Gradual learning rate warmup\n",
    "\n",
    "    # Evaluation and saving\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,  # Keep only 3 best checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # Generation settings (for validation)\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=100,\n",
    "    generation_num_beams=1,  # Use greedy decoding for faster validation\n",
    "\n",
    "    # Performance\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision for speed\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    report_to=\"none\",  # Disable wandb/tensorboard for simplicity\n",
    "\n",
    "    # Reproducibility\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Early stopping: stop if validation loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    "    early_stopping_threshold=0.0\n",
    ")\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Output directory: {output_dir}\")\n",
    "print(f\"  Mixed precision (fp16): {training_args.fp16}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 25: Define Custom Metrics for Evaluation\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for generated predictions during validation.\n",
    "\n",
    "    Metrics:\n",
    "    - Exact match accuracy (Top-1)\n",
    "    - Valid SMILES percentage\n",
    "    - Average token accuracy\n",
    "\n",
    "    Args:\n",
    "        eval_pred: EvalPrediction with predictions and labels\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # Replace -100 in labels with pad_token_id for decoding\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Clean predictions\n",
    "    decoded_preds = [pred.replace(' ', '').rstrip('.') for pred in decoded_preds]\n",
    "    decoded_labels = [label.replace(' ', '').rstrip('.') for label in decoded_labels]\n",
    "\n",
    "    # Canonicalize for comparison\n",
    "    canonical_preds = [canonicalize_smiles(pred) for pred in decoded_preds]\n",
    "    canonical_labels = [canonicalize_smiles(label) for label in decoded_labels]\n",
    "\n",
    "    # Calculate metrics\n",
    "    n_total = len(canonical_preds)\n",
    "    n_valid = sum(1 for pred in canonical_preds if pred != '')\n",
    "    n_correct = sum(1 for pred, label in zip(canonical_preds, canonical_labels)\n",
    "                    if pred != '' and pred == label)\n",
    "\n",
    "    return {\n",
    "        'accuracy': n_correct / n_total if n_total > 0 else 0,\n",
    "        'valid_smiles': n_valid / n_total if n_total > 0 else 0,\n",
    "    }\n",
    "\n",
    "print(\"Custom metrics function defined:\")\n",
    "print(\"  - Exact match accuracy\")\n",
    "print(\"  - Valid SMILES percentage\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 26: Fine-tune the Model\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning...\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training on {len(train_dataset)} reactions\")\n",
    "print(f\"Validating on {len(val_dataset)} reactions\")\n",
    "print(f\"This will take approximately 10-15 minutes on a T4 GPU\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train!\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total training time: {train_result.metrics['train_runtime']:.1f} seconds\")\n",
    "print(f\"Training loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "final_model_path = f\"{output_dir}/final_model\"\n",
    "trainer.save_model(final_model_path)\n",
    "print(f\"\\nFine-tuned model saved to: {final_model_path}\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 27: Visualize Training Progress\n",
    "\n",
    "# Extract training history\n",
    "history = trainer.state.log_history\n",
    "\n",
    "# Separate training and evaluation logs\n",
    "train_logs = [log for log in history if 'loss' in log and 'eval_loss' not in log]\n",
    "eval_logs = [log for log in history if 'eval_loss' in log]\n",
    "\n",
    "# Create DataFrames\n",
    "train_df = pd.DataFrame(train_logs)\n",
    "eval_df = pd.DataFrame(eval_logs)\n",
    "\n",
    "# Plot training and validation loss\n",
    "fig = go.Figure()\n",
    "\n",
    "if 'loss' in train_df.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train_df['step'],\n",
    "        y=train_df['loss'],\n",
    "        mode='lines+markers',\n",
    "        name='Training Loss',\n",
    "        line=dict(color=GOMES_COLORS['teal'], width=2),\n",
    "        marker=dict(size=6)\n",
    "    ))\n",
    "\n",
    "if 'eval_loss' in eval_df.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=eval_df['step'],\n",
    "        y=eval_df['eval_loss'],\n",
    "        mode='lines+markers',\n",
    "        name='Validation Loss',\n",
    "        line=dict(color=GOMES_COLORS['coral'], width=2),\n",
    "        marker=dict(size=8, symbol='diamond')\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=GOMES_TEMPLATE,\n",
    "    title='Fine-tuning Training Curves',\n",
    "    xaxis_title='Training Steps',\n",
    "    yaxis_title='Loss',\n",
    "    hovermode='x unified',\n",
    "    height=400,\n",
    "    legend=dict(x=0.7, y=0.95)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "if 'eval_accuracy' in eval_df.columns:\n",
    "    fig_acc = go.Figure()\n",
    "\n",
    "    fig_acc.add_trace(go.Scatter(\n",
    "        x=eval_df['epoch'],\n",
    "        y=eval_df['eval_accuracy'] * 100,\n",
    "        mode='lines+markers',\n",
    "        name='Validation Accuracy',\n",
    "        line=dict(color=GOMES_COLORS['success'], width=2),\n",
    "        marker=dict(size=10)\n",
    "    ))\n",
    "\n",
    "    fig_acc.update_layout(\n",
    "        template=GOMES_TEMPLATE,\n",
    "        title='Validation Accuracy Over Training',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis_title='Accuracy (%)',\n",
    "        yaxis_range=[0, 100],\n",
    "        height=400,\n",
    "    )\n",
    "\n",
    "    fig_acc.show()\n",
    "\n",
    "print(\"\\nFinal validation metrics:\")\n",
    "if len(eval_df) > 0:\n",
    "    final_metrics = eval_df.iloc[-1]\n",
    "    print(f\"  Validation Loss: {final_metrics['eval_loss']:.4f}\")\n",
    "    if 'eval_accuracy' in final_metrics:\n",
    "        print(f\"  Validation Accuracy: {final_metrics['eval_accuracy']*100:.1f}%\")\n",
    "    if 'eval_valid_smiles' in final_metrics:\n",
    "        print(f\"  Valid SMILES: {final_metrics['eval_valid_smiles']*100:.1f}%\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 28: Load and Test Fine-tuned Model\n",
    "\n",
    "# Clean up memory first\n",
    "del model\n",
    "del trainer\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Load the fine-tuned model\n",
    "print(\"Loading fine-tuned model...\")\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(final_model_path)\n",
    "finetuned_model.to(DEVICE)\n",
    "finetuned_model.eval()\n",
    "\n",
    "# Also keep the base model for comparison\n",
    "print(\"Loading base model for comparison...\")\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(\"sagawa/ReactionT5v2-forward\")\n",
    "base_model.to(DEVICE)\n",
    "base_model.eval()\n",
    "\n",
    "print(\"\\nModels loaded successfully!\")\n",
    "print(f\"Fine-tuned model: {final_model_path}\")\n",
    "print(f\"Base model: sagawa/ReactionT5v2-forward\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 29: Compare Base vs Fine-tuned Model\n",
    "\n",
    "def predict_with_model(model, tokenizer, reactants, reagents=\" \", num_beams=5):\n",
    "    \"\"\"Helper function to predict with a given model.\"\"\"\n",
    "    input_text = f\"REACTANT:{reactants}REAGENT:{reagents}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=num_beams,\n",
    "            num_return_sequences=1,\n",
    "            max_length=100,\n",
    "        )\n",
    "\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    pred = pred.replace(' ', '').rstrip('.')\n",
    "    return pred\n",
    "\n",
    "# Test on some validation examples\n",
    "print(\"Comparison: Base Model vs Fine-tuned Model\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load validation data\n",
    "val_data = pd.read_csv(val_csv)\n",
    "test_samples = val_data.head(10)\n",
    "\n",
    "results = []\n",
    "for idx, row in test_samples.iterrows():\n",
    "    reactants = row['REACTANT']\n",
    "    reagents = row['REAGENT']\n",
    "    expected = row['PRODUCT']\n",
    "\n",
    "    # Predict with both models\n",
    "    base_pred = predict_with_model(base_model, tokenizer, reactants, reagents)\n",
    "    finetuned_pred = predict_with_model(finetuned_model, tokenizer, reactants, reagents)\n",
    "\n",
    "    # Canonicalize\n",
    "    expected_canon = canonicalize_smiles(expected)\n",
    "    base_canon = canonicalize_smiles(base_pred)\n",
    "    finetuned_canon = canonicalize_smiles(finetuned_pred)\n",
    "\n",
    "    # Check correctness\n",
    "    base_correct = base_canon == expected_canon\n",
    "    finetuned_correct = finetuned_canon == expected_canon\n",
    "\n",
    "    results.append({\n",
    "        'Reactants': reactants[:40] + '...' if len(reactants) > 40 else reactants,\n",
    "        'Expected': expected_canon,\n",
    "        'Base': base_canon,\n",
    "        'Base Correct': '' if base_correct else '',\n",
    "        'Fine-tuned': finetuned_canon,\n",
    "        'FT Correct': '' if finetuned_correct else '',\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "base_accuracy = results_df['Base Correct'].value_counts().get('', 0) / len(results_df) * 100\n",
    "ft_accuracy = results_df['FT Correct'].value_counts().get('', 0) / len(results_df) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ACCURACY SUMMARY (on 10 validation samples):\")\n",
    "print(f\"  Base Model:       {base_accuracy:.0f}%\")\n",
    "print(f\"  Fine-tuned Model: {ft_accuracy:.0f}%\")\n",
    "print(f\"  Improvement:      {ft_accuracy - base_accuracy:+.0f}%\")\n",
    "print(\"=\" * 80)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 30: Comprehensive Evaluation on Full Validation Set\n",
    "\n",
    "def evaluate_model_on_dataset(model, tokenizer, csv_path, num_beams=5, max_samples=None):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a full dataset.\n",
    "\n",
    "    Args:\n",
    "        model: T5 model to evaluate\n",
    "        tokenizer: Tokenizer\n",
    "        csv_path: Path to validation CSV\n",
    "        num_beams: Beam search width\n",
    "        max_samples: Limit evaluation (None for all)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with predictions and metrics\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_path)\n",
    "    if max_samples:\n",
    "        data = data.head(max_samples)\n",
    "\n",
    "    results = []\n",
    "    for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Evaluating\"):\n",
    "        reactants = row['REACTANT']\n",
    "        reagents = row['REAGENT']\n",
    "        expected = row['PRODUCT']\n",
    "\n",
    "        # Predict\n",
    "        input_text = f\"REACTANT:{reactants}REAGENT:{reagents}\"\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                num_beams=num_beams,\n",
    "                num_return_sequences=min(num_beams, 5),\n",
    "                max_length=100,\n",
    "            )\n",
    "\n",
    "        # Decode all predictions\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            pred = tokenizer.decode(output, skip_special_tokens=True)\n",
    "            pred = pred.replace(' ', '').rstrip('.')\n",
    "            pred_canon = canonicalize_smiles(pred)\n",
    "            predictions.append(pred_canon)\n",
    "\n",
    "        # Check if expected is in predictions\n",
    "        expected_canon = canonicalize_smiles(expected)\n",
    "        try:\n",
    "            rank = predictions.index(expected_canon) + 1\n",
    "        except ValueError:\n",
    "            rank = 0  # Not found\n",
    "\n",
    "        results.append({\n",
    "            'reactants': reactants,\n",
    "            'reagents': reagents,\n",
    "            'expected': expected_canon,\n",
    "            'predicted_top1': predictions[0] if predictions else '',\n",
    "            'rank': rank,\n",
    "            'top1_correct': rank == 1,\n",
    "            'top5_correct': 0 < rank <= 5,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Evaluate both models on full validation set\n",
    "print(\"Evaluating Base Model on full validation set...\")\n",
    "base_eval = evaluate_model_on_dataset(base_model, tokenizer, val_csv, num_beams=5)\n",
    "\n",
    "print(\"\\nEvaluating Fine-tuned Model on full validation set...\")\n",
    "finetuned_eval = evaluate_model_on_dataset(finetuned_model, tokenizer, val_csv, num_beams=5)\n",
    "\n",
    "# Calculate metrics\n",
    "def print_metrics(eval_df, model_name):\n",
    "    n_total = len(eval_df)\n",
    "    top1_acc = eval_df['top1_correct'].sum() / n_total * 100\n",
    "    top5_acc = eval_df['top5_correct'].sum() / n_total * 100\n",
    "\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"  Top-1 Accuracy: {top1_acc:.1f}%\")\n",
    "    print(f\"  Top-5 Accuracy: {top5_acc:.1f}%\")\n",
    "    print(f\"  Total reactions: {n_total}\")\n",
    "\n",
    "    return {'top1': top1_acc, 'top5': top5_acc}\n",
    "\n",
    "base_metrics = print_metrics(base_eval, \"Base Model\")\n",
    "ft_metrics = print_metrics(finetuned_eval, \"Fine-tuned Model\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMPROVEMENT FROM FINE-TUNING:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Top-1 Accuracy: {base_metrics['top1']:.1f}%  {ft_metrics['top1']:.1f}% ({ft_metrics['top1'] - base_metrics['top1']:+.1f}%)\")\n",
    "print(f\"Top-5 Accuracy: {base_metrics['top5']:.1f}%  {ft_metrics['top5']:.1f}% ({ft_metrics['top5'] - base_metrics['top5']:+.1f}%)\")\n",
    "print(\"=\" * 70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 31: Visualize Performance Comparison\n",
    "\n",
    "# Bar chart comparison\n",
    "comparison_data = [\n",
    "    {'Model': 'Base Model', 'Top-1': base_metrics['top1'], 'Top-5': base_metrics['top5']},\n",
    "    {'Model': 'Fine-tuned', 'Top-1': ft_metrics['top1'], 'Top-5': ft_metrics['top5']},\n",
    "]\n",
    "comp_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=comp_df['Model'],\n",
    "    y=comp_df['Top-1'],\n",
    "    name='Top-1 Accuracy',\n",
    "    marker_color=GOMES_COLORS['teal'],\n",
    "    text=[f\"{v:.1f}%\" for v in comp_df['Top-1']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=comp_df['Model'],\n",
    "    y=comp_df['Top-5'],\n",
    "    name='Top-5 Accuracy',\n",
    "    marker_color=GOMES_COLORS['coral'],\n",
    "    text=[f\"{v:.1f}%\" for v in comp_df['Top-5']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    template=GOMES_TEMPLATE,\n",
    "    title='Base Model vs Fine-tuned Model Performance',\n",
    "    yaxis_title='Accuracy (%)',\n",
    "    yaxis_range=[0, 105],\n",
    "    barmode='group',\n",
    "    height=450,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Show examples where fine-tuning helped\n",
    "print(\"\\nExamples where fine-tuning improved predictions:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "improved_examples = []\n",
    "for base_row, ft_row in zip(base_eval.itertuples(), finetuned_eval.itertuples()):\n",
    "    if not base_row.top1_correct and ft_row.top1_correct:\n",
    "        improved_examples.append({\n",
    "            'Reactants': base_row.reactants[:50] + '...',\n",
    "            'Expected': base_row.expected,\n",
    "            'Base Pred': base_row.predicted_top1,\n",
    "            'FT Pred': ft_row.predicted_top1,\n",
    "        })\n",
    "\n",
    "    if len(improved_examples) >= 5:  # Show first 5\n",
    "        break\n",
    "\n",
    "if improved_examples:\n",
    "    improved_df = pd.DataFrame(improved_examples)\n",
    "    print(improved_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Fine-tuning matched or exceeded base model on all samples!\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning Best Practices and Tips\n\n#### 1. **Data Quality Over Quantity**\n\nFine-tuning can succeed with as few as 100-200 reactions, but data quality is critical:\n- Ensure SMILES are valid and canonical\n- Remove duplicates and contradictory examples\n- Balance different reaction subtypes\n- Include diverse substituent patterns\n\n#### 2. **Hyperparameter Tuning**\n\nKey parameters to adjust based on your dataset:\n\n| Parameter | Small Dataset (<500) | Large Dataset (>5000) |\n|-----------|---------------------|----------------------|\n| Learning Rate | 5e-5 to 1e-4 | 1e-4 to 1e-3 |\n| Epochs | 15-30 | 5-10 |\n| Batch Size | 8-16 | 32-64 |\n| Warmup Steps | 20-50 | 100-500 |\n\n#### 3. **Data Augmentation**\n\nSMILES randomization significantly improves generalization:\n- Apply `randomize_smiles()` to training reactants (not products!)\n- Augment 2-5x for small datasets\n- Use \"unrestricted\" randomization for maximum diversity\n\n#### 4. **Validation Strategy**\n\n- Use **random split** if reactions are diverse\n- Use **scaffold split** if testing on novel scaffolds\n- Monitor both accuracy AND valid SMILES percentage\n- Implement early stopping to prevent overfitting\n\n#### 5. **When Fine-tuning May Not Help**\n\nFine-tuning is less beneficial when:\n- Your reactions are already well-represented in ORD/USPTO\n- You have <50 training examples (too small)\n- Reaction conditions (not reagents) are the key variable\n- You need yield prediction (different task)\n\n#### 6. **Transfer Learning Strategy**\n\nFor related but different reaction types:\n1. Start from ReactionT5v2-forward (not T5-base)\n2. Use a lower learning rate (1e-4 vs 1e-3)\n3. Fine-tune for fewer epochs (10-20 vs 100)\n4. Monitor validation loss closely\n\n#### 7. **Production Considerations**\n\n- Save multiple checkpoints during training\n- Test on held-out test set before deployment\n- Consider ensemble predictions (multiple fine-tuned models)\n- Monitor prediction confidence (beam scores)\n- Set up automated retraining as new data arrives\n\n#### 8. **Common Pitfalls**\n\n| Problem | Solution |\n|---------|----------|\n| Model predicts training data verbatim | Reduce epochs, increase dropout |\n| High loss, low accuracy | Check data format, increase learning rate |\n| Invalid SMILES outputs | Add SMILES validation to training loop |\n| Out of memory errors | Reduce batch size, use gradient accumulation |\n| Slow training | Enable fp16, reduce max_length, use fewer beams |\n\n#### 9. **Debugging Tips**\n\nIf fine-tuning doesn't improve performance:\n1. Check that base model makes errors on your validation set\n2. Verify data format matches expected input\n3. Ensure products are canonical (not randomized)\n4. Try training for more epochs\n5. Inspect training loss - should decrease steadily\n\n#### 10. **Extension Ideas**\n\n- Fine-tune on reaction **yield** prediction\n- Multi-task learning (product + yield simultaneously)\n- Add reaction **condition** optimization\n- Incorporate reaction **mechanism** classification\n- Build reagent recommendation system\n\n---\n\n**Key Takeaway**: Fine-tuning ReactionT5v2 is highly effective for domain-specific reaction prediction, often achieving >95% accuracy with just 200-500 examples. The pre-trained model provides excellent chemical knowledge, and fine-tuning adapts it to your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 33: Save and Export Fine-tuned Model\n",
    "\n",
    "# Model is already saved in final_model_path, but let's add export instructions\n",
    "\n",
    "print(\"Fine-tuned Model Export Options\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n1. LOCAL USAGE:\")\n",
    "print(f\"   Model saved at: {final_model_path}\")\n",
    "print(f\"   Load with:\")\n",
    "print(f\"   ```python\")\n",
    "print(f\"   from transformers import AutoTokenizer, T5ForConditionalGeneration\")\n",
    "print(f\"   model = T5ForConditionalGeneration.from_pretrained('{final_model_path}')\")\n",
    "print(f\"   tokenizer = AutoTokenizer.from_pretrained('{final_model_path}')\")\n",
    "print(f\"   ```\")\n",
    "\n",
    "print(f\"\\n2. HUGGING FACE HUB (Optional):\")\n",
    "print(f\"   To share your model publicly:\")\n",
    "print(f\"   ```python\")\n",
    "print(f\"   model.push_to_hub('your-username/reactiont5-suzuki-coupling')\")\n",
    "print(f\"   tokenizer.push_to_hub('your-username/reactiont5-suzuki-coupling')\")\n",
    "print(f\"   ```\")\n",
    "\n",
    "print(f\"\\n3. GOOGLE COLAB DOWNLOAD:\")\n",
    "if IN_COLAB:\n",
    "    print(f\"   Run this to download the model:\")\n",
    "    print(f\"   ```python\")\n",
    "    print(f\"   from google.colab import files\")\n",
    "    print(f\"   !zip -r finetuned_model.zip {final_model_path}\")\n",
    "    print(f\"   files.download('finetuned_model.zip')\")\n",
    "    print(f\"   ```\")\n",
    "else:\n",
    "    print(f\"   (Google Colab-specific - skipped)\")\n",
    "\n",
    "print(f\"\\n4. MODEL CARD:\")\n",
    "print(f\"   Consider creating a model card documenting:\")\n",
    "print(f\"   - Training data source and size\")\n",
    "print(f\"   - Fine-tuning hyperparameters\")\n",
    "print(f\"   - Performance metrics\")\n",
    "print(f\"   - Intended use cases and limitations\")\n",
    "print(f\"   - Example usage\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Fine-tuning section complete!\")\n",
    "print(\"=\" * 70)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Visualization and Analysis\n",
    "\n",
    "<a id='4.1'></a>\n",
    "### 4.1 Drawing Chemical Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Enhanced Reaction Drawing\n",
    "\n",
    "def draw_reaction_comparison(precursors: str, predicted: str, expected: str,\n",
    "                             title: str = \"Reaction Comparison\") -> None:\n",
    "    \"\"\"\n",
    "    Draw predicted vs expected reaction products side by side.\n",
    "    \n",
    "    Args:\n",
    "        precursors: SMILES of reactants\n",
    "        predicted: Predicted product SMILES\n",
    "        expected: Ground truth product SMILES\n",
    "        title: Display title\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    \n",
    "    pred_canonical = canonicalize_smiles(predicted)\n",
    "    exp_canonical = canonicalize_smiles(expected)\n",
    "    is_correct = pred_canonical == exp_canonical\n",
    "    \n",
    "    status_color = GOMES_COLORS['success'] if is_correct else GOMES_COLORS['coral']\n",
    "    status_text = \"CORRECT\" if is_correct else \"INCORRECT\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"border: 2px solid {status_color}; padding: 15px; margin: 10px 0; border-radius: 8px;\">\n",
    "        <h3 style=\"color: {GOMES_COLORS['navy']};\">{title}</h3>\n",
    "        <p><strong>Status:</strong> <span style=\"color: {status_color}; font-weight: bold;\">{status_text}</span></p>\n",
    "        <p><strong>Reactants:</strong> <code>{precursors}</code></p>\n",
    "        <p><strong>Predicted:</strong> <code>{predicted}</code></p>\n",
    "        <p><strong>Expected:</strong> <code>{expected}</code></p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Draw the predicted reaction\n",
    "    rxn_smiles = f\"{precursors}>>{predicted}\"\n",
    "    try:\n",
    "        display(SVG(draw_chemical_reaction(rxn_smiles)))\n",
    "    except:\n",
    "        print(\"(Could not render reaction)\")\n",
    "\n",
    "# Show some examples from our evaluation\n",
    "print(\"Sample Predictions from Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show correct predictions\n",
    "correct_samples = eval_results[eval_results['rank'] == 1].head(3)\n",
    "for _, row in correct_samples.iterrows():\n",
    "    draw_reaction_comparison(\n",
    "        row['precursors'],\n",
    "        row['pred_1'],\n",
    "        row['target_canonical'],\n",
    "        \"Correct Prediction\"\n",
    "    )\n",
    "\n",
    "# Show incorrect predictions\n",
    "incorrect_samples = eval_results[eval_results['rank'] == 0].head(2)\n",
    "for _, row in incorrect_samples.iterrows():\n",
    "    draw_reaction_comparison(\n",
    "        row['precursors'],\n",
    "        row['pred_1'],\n",
    "        row['target_canonical'],\n",
    "        \"Incorrect Prediction\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "### 4.2 Error Analysis and Debugging\n",
    "\n",
    "Understanding why predictions fail is crucial for improving models and understanding their limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Error Analysis\n",
    "\n",
    "def analyze_prediction_errors(results_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze types of prediction errors.\n",
    "    \n",
    "    Categories:\n",
    "    - Invalid SMILES: Model output couldn't be parsed\n",
    "    - Wrong product: Valid SMILES but incorrect\n",
    "    - Partial match: Correct in later predictions (Top-2 to Top-5)\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from evaluate_predictions\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with error statistics\n",
    "    \"\"\"\n",
    "    n_total = len(results_df)\n",
    "    \n",
    "    # Categorize errors\n",
    "    correct_top1 = (results_df['rank'] == 1).sum()\n",
    "    correct_top5 = (results_df['rank'] > 0).sum()\n",
    "    invalid_smiles = (~results_df['pred_1_valid']).sum()\n",
    "    wrong_but_valid = (results_df['rank'] == 0) & (results_df['pred_1_valid'])\n",
    "    \n",
    "    analysis = {\n",
    "        'total_reactions': n_total,\n",
    "        'correct_top1': correct_top1,\n",
    "        'correct_top1_pct': correct_top1 / n_total * 100,\n",
    "        'correct_top5': correct_top5,\n",
    "        'correct_top5_pct': correct_top5 / n_total * 100,\n",
    "        'invalid_smiles': invalid_smiles,\n",
    "        'invalid_smiles_pct': invalid_smiles / n_total * 100,\n",
    "        'wrong_but_valid': wrong_but_valid.sum(),\n",
    "        'wrong_but_valid_pct': wrong_but_valid.sum() / n_total * 100,\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Run error analysis\n",
    "error_analysis = analyze_prediction_errors(eval_results)\n",
    "\n",
    "print(\"Error Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total reactions evaluated: {error_analysis['total_reactions']}\")\n",
    "print(f\"\")\n",
    "print(f\"Correct (Top-1): {error_analysis['correct_top1']} ({error_analysis['correct_top1_pct']:.1f}%)\")\n",
    "print(f\"Correct (Top-5): {error_analysis['correct_top5']} ({error_analysis['correct_top5_pct']:.1f}%)\")\n",
    "print(f\"Invalid SMILES: {error_analysis['invalid_smiles']} ({error_analysis['invalid_smiles_pct']:.1f}%)\")\n",
    "print(f\"Wrong but valid: {error_analysis['wrong_but_valid']} ({error_analysis['wrong_but_valid_pct']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Common Failure Patterns\n",
    "\n",
    "print(\"\"\"\n",
    "Common Failure Patterns in Reaction Prediction\n",
    "===============================================\n",
    "\n",
    "1. STEREOCHEMISTRY ERRORS\n",
    "   - Model predicts correct connectivity but wrong stereochemistry\n",
    "   - Often seen in reactions involving chiral centers\n",
    "   - The USPTO dataset lacks stereochemistry, so models may struggle\n",
    "\n",
    "2. REGIOSELECTIVITY ERRORS\n",
    "   - Model predicts reaction at wrong position on molecule\n",
    "   - Common for aromatic substitution reactions\n",
    "   - Example: ortho vs para product in electrophilic substitution\n",
    "\n",
    "3. INCOMPLETE REACTIONS\n",
    "   - Model predicts only partial transformation\n",
    "   - May miss side products or byproducts\n",
    "   - Common for multi-step reactions treated as single step\n",
    "\n",
    "4. OVER-GENERALIZATION\n",
    "   - Model predicts common reaction type inappropriately\n",
    "   - May suggest Suzuki coupling when conditions don't support it\n",
    "   - Result of training data bias\n",
    "\n",
    "5. INVALID SMILES\n",
    "   - Model generates syntactically invalid output\n",
    "   - Often happens with very long molecules\n",
    "   - May indicate out-of-distribution inputs\n",
    "\n",
    "Debugging Tips:\n",
    "   - Always validate output SMILES with RDKit\n",
    "   - Check if reactants contain unusual functional groups\n",
    "   - Consider whether reaction type was in training data\n",
    "   - Use beam search (multiple predictions) to see alternatives\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='appendix-a'></a>\n",
    "## Appendix A: Legacy OpenNMT-py Approach (Reference Only)\n",
    "\n",
    "The original 2022 notebook used OpenNMT-py for training Molecular Transformers. While this approach is now deprecated, understanding the architecture is still valuable.\n",
    "\n",
    "**Why OpenNMT-py is no longer recommended:**\n",
    "\n",
    "1. **Maintenance Mode**: As of July 2024, OpenNMT-py is no longer actively developed. The successor project is [Eole](https://github.com/eole-nlp/eole).\n",
    "\n",
    "2. **Dependency Issues**: The `pyonmttok` tokenizer doesn't support Python 3.12 (Google Colab's current version).\n",
    "\n",
    "3. **Better Alternatives**: HuggingFace Transformers offers better ecosystem integration, more models, and active development.\n",
    "\n",
    "For historical reference, the key OpenNMT-py commands were:\n",
    "\n",
    "```bash\n",
    "# Build vocabulary\n",
    "onmt_build_vocab -config config.yaml -n_sample -1\n",
    "\n",
    "# Train model\n",
    "onmt_train -config config.yaml -seed 42 -gpu_ranks 0 ...\n",
    "\n",
    "# Translate (predict)\n",
    "onmt_translate -model model.pt -src test_src.txt -output predictions.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix-b'></a>\n",
    "## Appendix B: Publications and Resources\n",
    "\n",
    "### Core Papers\n",
    "\n",
    "**Molecular Transformer:**\n",
    "- Schwaller, P. et al. \"Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\" *ACS Central Science* (2019) [Link](https://pubs.acs.org/doi/10.1021/acscentsci.9b00576)\n",
    "\n",
    "**ReactionT5:**\n",
    "- Sagawa, T. & Kojima, R. \"ReactionT5: a pre-trained transformer model for accurate chemical reaction prediction with limited data\" *Journal of Cheminformatics* (2025) [Link](https://doi.org/10.1186/s13321-025-01075-4)\n",
    "\n",
    "**RXNMapper:**\n",
    "- Schwaller, P. et al. \"Extraction of organic chemistry grammar from unsupervised learning of chemical reactions\" *Science Advances* (2021) [Link](https://www.science.org/doi/10.1126/sciadv.abe4166)\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "**Tutorials and Blogs:**\n",
    "- [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) - Visual explanation of transformer architecture\n",
    "- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html) - Code walkthrough\n",
    "\n",
    "**Tools and Datasets:**\n",
    "- [Open Reaction Database (ORD)](https://open-reaction-database.org/) - Large-scale reaction data\n",
    "- [IBM RXN for Chemistry](https://rxn.res.ibm.com) - Production API\n",
    "- [RDKit](https://www.rdkit.org/) - Cheminformatics toolkit\n",
    "\n",
    "**Review Papers:**\n",
    "- Schwaller, P. \"Machine Intelligence for Chemical Reaction Space\" *WIREs Computational Molecular Science* (2022) [Link](https://wires.onlinelibrary.wiley.com/doi/full/10.1002/wcms.1604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Session Summary\n",
    "\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "                    SESSION SUMMARY: REACTION PREDICTION\n",
    "================================================================================\n",
    "\n",
    "Key Takeaways:\n",
    "\n",
    "1. SMILES as Chemical Language\n",
    "   - Molecules and reactions can be represented as text strings\n",
    "   - Canonicalization ensures consistent representation\n",
    "   - Atom-wise tokenization preserves chemical meaning\n",
    "\n",
    "2. Transformer Models for Chemistry\n",
    "   - Treat reaction prediction as sequence-to-sequence translation\n",
    "   - Self-attention captures long-range dependencies in molecules\n",
    "   - Pre-training on large datasets enables transfer learning\n",
    "\n",
    "3. ReactionT5v2 Advantages\n",
    "   - Pre-trained on diverse Open Reaction Database\n",
    "   - Easy fine-tuning for specialized applications\n",
    "   - Works out-of-the-box on Google Colab\n",
    "\n",
    "4. Practical Considerations\n",
    "   - Always validate output SMILES\n",
    "   - Use beam search for multiple predictions\n",
    "   - Data augmentation improves generalization\n",
    "   - Consider API services for production use\n",
    "\n",
    "Next Steps:\n",
    "   - Try fine-tuning on your own reaction dataset\n",
    "   - Explore retrosynthesis for synthesis planning\n",
    "   - Integrate with reaction fingerprints (RXNFP/DRFP)\n",
    "   - Investigate yield prediction capabilities\n",
    "\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: Clean up GPU memory\n",
    "import gc\n",
    "\n",
    "# Clean up models to free memory\n",
    "if 'forward_predictor' in dir():\n",
    "    del forward_predictor\n",
    "if 'retro_predictor' in dir():\n",
    "    del retro_predictor\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"GPU memory cleared. Current usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Session complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}